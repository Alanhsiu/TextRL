{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5gZSqIG1ah"
   },
   "source": [
    "# Controllable generation via RL to let Elon Musk speak ill of DOGE\n",
    "> How to control text generation through a sentiment classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from transformers import (AutoTokenizer, BartForConditionalGeneration)\n",
    "\n",
    "# define path\n",
    "base_path = '/work/b0990106x/TextRL'\n",
    "agent_input_dir = f'{base_path}/data-encodec'\n",
    "agent_output_dir = f'{base_path}/output-predict'\n",
    "env_input_dir = agent_output_dir\n",
    "env_output_dir = agent_input_dir\n",
    "\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "ar_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(agent_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_src_encodec_layers = []\n",
    "all_src_encodec = []\n",
    "all_instruction = []\n",
    "all_instruction_ids = []\n",
    "\n",
    "data_len = len(dataset)\n",
    "print(data_len)\n",
    "\n",
    "layer_len = 8\n",
    "\n",
    "for i in range(layer_len):\n",
    "    all_src_encodec_layers.append(dataset[f\"src_encodec_{i}\"])\n",
    "\n",
    "for i in range(data_len):\n",
    "    src_encodec = []\n",
    "    for j in range(layer_len):        \n",
    "        src_encodec.append(all_src_encodec_layers[j][i])\n",
    "    all_src_encodec.append(src_encodec)\n",
    "\n",
    "for i in range(data_len):\n",
    "    all_instruction.append(dataset[\"instruction\"][i])\n",
    "    all_instruction_ids.append(ar_tokenizer(all_instruction[i])[\"input_ids\"][1 : -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import textrl\n",
    "reload(textrl)\n",
    "from textrl import TextRLEnv,TextRLActor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NISQA.nisqa.NISQA_model import nisqaModel\n",
    "\n",
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
    "        reward = 0\n",
    "        \n",
    "        if finish or len(predicted_list) >= self.env_max_length:\n",
    "            try:\n",
    "                # debug 0423\n",
    "                print(\"Length of predicted_list:\", len(predicted_list[0]))\n",
    "\n",
    "                args_nisqa = {\n",
    "                    'mode': 'predict_file', \n",
    "                    'pretrained_model': f'{base_path}/NISQA/weights/nisqa.tar', \n",
    "                    'deg': f'{base_path}/output-predict/example.wav', \n",
    "                    'data_dir': None, \n",
    "                    'output_dir': f'{base_path}/NISQA/result-predict',\n",
    "                    'csv_file': None, \n",
    "                    'csv_deg': None,  \n",
    "                    'num_workers': 0, \n",
    "                    'bs': 1,\n",
    "                    'ms_channel': None\n",
    "                }\n",
    "                args_nisqa['tr_bs_val'] = args_nisqa['bs']\n",
    "                args_nisqa['tr_num_workers'] = args_nisqa['num_workers']\n",
    "\n",
    "                nisqa = nisqaModel(args_nisqa)\n",
    "                prediction = nisqa.predict()\n",
    "                reward = float(prediction['mos_pred'].iloc[0])\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "                reward = 0\n",
    "                \n",
    "            print(\"Reward:\", reward)\n",
    "\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqF7mNCY5tdO"
   },
   "source": [
    "**fit one example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_list = []\n",
    "\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "# observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[0], 'instruction': all_instruction[0]})\n",
    "\n",
    "for i in range(data_len):\n",
    "    observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[i], 'instruction': all_instruction[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wtGfk03eHOv_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name:  BartForConditionalGeneration\n",
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 0 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_0.wav\n"
     ]
    }
   ],
   "source": [
    "env = MyRLEnv(ar_model, ar_tokenizer, nar_model, nar_tokenizer, observation_input=observation_list, compare_sample=1)\n",
    "actor = TextRLActor(env, ar_model, ar_tokenizer)\n",
    "agent = actor.agent_ppo(update_interval=3, minibatch_size=3, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B7rMPRU5zsM"
   },
   "source": [
    "loading the best result and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensify the sound of the higher frequencies.\n"
     ]
    }
   ],
   "source": [
    "print(observation_list[5][\"instruction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 1 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_1.wav\n",
      "Length of predicted_list: 650\n",
      "n_wins 851  seg_length 15  x.shape[1] 865\n",
      "x.shape torch.Size([1300, 1, 48, 15])  n_wins 851\n",
      "Reward: 2.37109375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['v_tok_408v_tok_835v_tok_835v_tok_798v_tok_585v_tok_550v_tok_535v_tok_535v_tok_737v_tok_737v_tok_377v_tok_556v_tok_601v_tok_787v_tok_8v_tok_99v_tok_411v_tok_411v_tok_378v_tok_937v_tok_378v_tok_937v_tok_804v_tok_838v_tok_890v_tok_934v_tok_47v_tok_438v_tok_438v_tok_731v_tok_738v_tok_133v_tok_709v_tok_479v_tok_479v_tok_479v_tok_151v_tok_940v_tok_502v_tok_906v_tok_407v_tok_645v_tok_70v_tok_208v_tok_537v_tok_537v_tok_1022v_tok_681v_tok_723v_tok_747v_tok_593v_tok_804v_tok_681v_tok_879v_tok_136v_tok_967v_tok_233v_tok_431v_tok_754v_tok_421v_tok_182v_tok_182v_tok_651v_tok_879v_tok_887v_tok_819v_tok_904v_tok_904v_tok_887v_tok_309v_tok_880v_tok_396v_tok_754v_tok_775v_tok_997v_tok_222v_tok_336v_tok_548v_tok_841v_tok_269v_tok_479v_tok_479v_tok_940v_tok_23v_tok_56v_tok_738v_tok_835v_tok_395v_tok_206v_tok_779v_tok_531v_tok_862v_tok_931v_tok_306v_tok_203v_tok_755v_tok_369v_tok_6v_tok_466v_tok_716v_tok_948v_tok_82v_tok_575v_tok_288v_tok_556v_tok_903v_tok_556v_tok_392v_tok_796v_tok_751v_tok_835v_tok_103v_tok_25v_tok_408v_tok_835v_tok_835v_tok_339v_tok_339v_tok_395v_tok_250v_tok_706v_tok_317v_tok_479v_tok_1003v_tok_960v_tok_141v_tok_479v_tok_908v_tok_801v_tok_327v_tok_937v_tok_559v_tok_708v_tok_372v_tok_372v_tok_573v_tok_437v_tok_437v_tok_421v_tok_203v_tok_739v_tok_830v_tok_739v_tok_358v_tok_830v_tok_248v_tok_411v_tok_411v_tok_112v_tok_321v_tok_23v_tok_23v_tok_185v_tok_971v_tok_62v_tok_339v_tok_461v_tok_488v_tok_934v_tok_148v_tok_373v_tok_561v_tok_681v_tok_760v_tok_531v_tok_612v_tok_699v_tok_23v_tok_967v_tok_457v_tok_790v_tok_154v_tok_906v_tok_465v_tok_502v_tok_884v_tok_479v_tok_246v_tok_820v_tok_601v_tok_309v_tok_716v_tok_314v_tok_377v_tok_309v_tok_309v_tok_556v_tok_118v_tok_99v_tok_358v_tok_1018v_tok_862v_tok_779v_tok_62v_tok_835v_tok_25v_tok_254v_tok_254v_tok_677v_tok_73v_tok_143v_tok_696v_tok_696v_tok_321v_tok_879v_tok_23v_tok_224v_tok_523v_tok_23v_tok_835v_tok_835v_tok_835v_tok_475v_tok_59v_tok_257v_tok_819v_tok_472v_tok_835v_tok_835v_tok_738v_tok_339v_tok_835v_tok_835v_tok_1017v_tok_339v_tok_428v_tok_982v_tok_869v_tok_270v_tok_435v_tok_283v_tok_804v_tok_976v_tok_875v_tok_598v_tok_353v_tok_860v_tok_409v_tok_411v_tok_601v_tok_650v_tok_495v_tok_62v_tok_835v_tok_835v_tok_141v_tok_948v_tok_82v_tok_414v_tok_658v_tok_321v_tok_224v_tok_321v_tok_931v_tok_3v_tok_99v_tok_8v_tok_220v_tok_775v_tok_739v_tok_870v_tok_830v_tok_739v_tok_830v_tok_695v_tok_695v_tok_704v_tok_208v_tok_860v_tok_1001v_tok_982v_tok_240v_tok_593v_tok_830v_tok_411v_tok_63v_tok_855v_tok_1017v_tok_835v_tok_835v_tok_430v_tok_339v_tok_339v_tok_339v_tok_254v_tok_254v_tok_38v_tok_677v_tok_73v_tok_868v_tok_598v_tok_563v_tok_890v_tok_598v_tok_224v_tok_598v_tok_676v_tok_860v_tok_635v_tok_310v_tok_208v_tok_224v_tok_676v_tok_491v_tok_321v_tok_699v_tok_136v_tok_432v_tok_1019v_tok_475v_tok_537v_tok_176v_tok_176v_tok_436v_tok_373v_tok_160v_tok_709v_tok_339v_tok_339v_tok_835v_tok_339v_tok_475v_tok_537v_tok_1017v_tok_835v_tok_876v_tok_835v_tok_339v_tok_835v_tok_798v_tok_723v_tok_425v_tok_535v_tok_314v_tok_600v_tok_314v_tok_771v_tok_550v_tok_601v_tok_601v_tok_51v_tok_99v_tok_411v_tok_601v_tok_980v_tok_74v_tok_937v_tok_181v_tok_657v_tok_154v_tok_533v_tok_934v_tok_47v_tok_574v_tok_488v_tok_373v_tok_133v_tok_133v_tok_339v_tok_206v_tok_479v_tok_170v_tok_907v_tok_502v_tok_906v_tok_704v_tok_1021v_tok_645v_tok_1001v_tok_208v_tok_537v_tok_25v_tok_1022v_tok_681v_tok_99v_tok_358v_tok_830v_tok_804v_tok_681v_tok_1011v_tok_136v_tok_967v_tok_411v_tok_431v_tok_754v_tok_754v_tok_182v_tok_182v_tok_967v_tok_879v_tok_819v_tok_819v_tok_904v_tok_604v_tok_935v_tok_309v_tok_880v_tok_941v_tok_754v_tok_775v_tok_51v_tok_222v_tok_336v_tok_695v_tok_841v_tok_695v_tok_479v_tok_479v_tok_906v_tok_23v_tok_56v_tok_408v_tok_738v_tok_395v_tok_206v_tok_276v_tok_531v_tok_862v_tok_11v_tok_203v_tok_203v_tok_82v_tok_369v_tok_6v_tok_532v_tok_716v_tok_948v_tok_755v_tok_688v_tok_348v_tok_556v_tok_903v_tok_99v_tok_392v_tok_796v_tok_344v_tok_835v_tok_103v_tok_463v_tok_408v_tok_835v_tok_1017v_tok_834v_tok_339v_tok_395v_tok_816v_tok_1003v_tok_317v_tok_479v_tok_800v_tok_801v_tok_341v_tok_479v_tok_908v_tok_959v_tok_327v_tok_937v_tok_916v_tok_708v_tok_372v_tok_431v_tok_573v_tok_437v_tok_1018v_tok_203v_tok_739v_tok_358v_tok_739v_tok_387v_tok_358v_tok_747v_tok_411v_tok_411v_tok_411v_tok_99v_tok_23v_tok_860v_tok_291v_tok_185v_tok_1019v_tok_133v_tok_835v_tok_798v_tok_794v_tok_934v_tok_148v_tok_537v_tok_182v_tok_681v_tok_926v_tok_722v_tok_813v_tok_604v_tok_457v_tok_967v_tok_457v_tok_686v_tok_502v_tok_407v_tok_906v_tok_465v_tok_1000v_tok_956v_tok_937v_tok_222v_tok_716v_tok_314v_tok_567v_tok_309v_tok_309v_tok_309v_tok_716v_tok_771v_tok_358v_tok_747v_tok_1018v_tok_862v_tok_408v_tok_62v_tok_835v_tok_677v_tok_254v_tok_254v_tok_537v_tok_73v_tok_143v_tok_868v_tok_20v_tok_321v_tok_879v_tok_1001v_tok_224v_tok_523v_tok_276v_tok_835v_tok_835v_tok_1019v_tok_339v_tok_59v_tok_257v_tok_433v_tok_887v_tok_835v_tok_835v_tok_106v_tok_738v_tok_835v_tok_835v_tok_395v_tok_835v_tok_428v_tok_982v_tok_401v_tok_270v_tok_435v_tok_886v_tok_804v_tok_976v_tok_1001v_tok_598v_tok_353v_tok_971v_tok_777v_tok_601v_tok_568v_tok_937v_tok_495v_tok_835v_tok_133v_tok_835v_tok_141v_tok_846v_tok_82v_tok_688v_tok_658v_tok_321v_tok_136v_tok_967v_tok_858v_tok_646v_tok_197v_tok_8v_tok_220v_tok_284v_tok_739v_tok_870v_tok_870v_tok_739v_tok_387v_tok_739v_tok_198v_tok_860v_tok_976v_tok_1001v_tok_982v_tok_747v_tok_830v_tok_830v_tok_317v_tok_317v_tok_855v_tok_430v_tok_835v_tok_835v_tok_228v_tok_835v_tok_339v_tok_677v_tok_254v_tok_145v_tok_38v_tok_677v_tok_325v_tok_687v_tok_598v_tok_563v_tok_424v_tok_598v_tok_860v_tok_598v_tok_676v_tok_676v_tok_676v_tok_208v_tok_208v_tok_224v_tok_635v_tok_491v_tok_321v_tok_224v_tok_491v_tok_430v_tok_475v_tok_537v_tok_798v_tok_176v_tok_907v_tok_373v_tok_160v_tok_463v_tok_339v_tok_339v_tok_876v_tok_339v_tok_475v_tok_395v_tok_475v_tok_835v_tok_835</s>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.predict(observation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FrkYGPjYTIcS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 2 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_2.wav\n",
      "Length of predicted_list: 652\n",
      "n_wins 853  seg_length 15  x.shape[1] 867\n",
      "x.shape torch.Size([1300, 1, 48, 15])  n_wins 853\n",
      "Reward: 2.310546875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['v_tok_835v_tok_835v_tok_835v_tok_798v_tok_585v_tok_550v_tok_535v_tok_535v_tok_737v_tok_737v_tok_377v_tok_556v_tok_601v_tok_787v_tok_8v_tok_99v_tok_411v_tok_411v_tok_378v_tok_937v_tok_378v_tok_937v_tok_804v_tok_838v_tok_890v_tok_934v_tok_47v_tok_438v_tok_438v_tok_731v_tok_738v_tok_133v_tok_709v_tok_479v_tok_479v_tok_479v_tok_151v_tok_940v_tok_502v_tok_906v_tok_407v_tok_645v_tok_70v_tok_208v_tok_537v_tok_537v_tok_1022v_tok_681v_tok_723v_tok_747v_tok_593v_tok_804v_tok_681v_tok_879v_tok_136v_tok_967v_tok_233v_tok_431v_tok_754v_tok_421v_tok_182v_tok_182v_tok_651v_tok_879v_tok_887v_tok_819v_tok_904v_tok_904v_tok_887v_tok_309v_tok_880v_tok_396v_tok_754v_tok_775v_tok_997v_tok_222v_tok_336v_tok_548v_tok_841v_tok_269v_tok_479v_tok_479v_tok_940v_tok_23v_tok_56v_tok_738v_tok_835v_tok_395v_tok_206v_tok_779v_tok_531v_tok_862v_tok_931v_tok_306v_tok_203v_tok_755v_tok_369v_tok_6v_tok_466v_tok_716v_tok_948v_tok_82v_tok_575v_tok_288v_tok_556v_tok_903v_tok_556v_tok_392v_tok_796v_tok_751v_tok_835v_tok_103v_tok_25v_tok_408v_tok_835v_tok_835v_tok_339v_tok_339v_tok_395v_tok_250v_tok_706v_tok_317v_tok_479v_tok_800v_tok_960v_tok_141v_tok_479v_tok_908v_tok_801v_tok_327v_tok_937v_tok_559v_tok_708v_tok_372v_tok_372v_tok_573v_tok_437v_tok_437v_tok_421v_tok_203v_tok_739v_tok_830v_tok_739v_tok_358v_tok_830v_tok_248v_tok_411v_tok_411v_tok_112v_tok_321v_tok_23v_tok_23v_tok_185v_tok_971v_tok_62v_tok_339v_tok_461v_tok_488v_tok_934v_tok_148v_tok_373v_tok_561v_tok_681v_tok_760v_tok_531v_tok_612v_tok_699v_tok_23v_tok_967v_tok_457v_tok_790v_tok_154v_tok_906v_tok_465v_tok_502v_tok_884v_tok_479v_tok_246v_tok_820v_tok_601v_tok_309v_tok_716v_tok_314v_tok_377v_tok_309v_tok_309v_tok_556v_tok_118v_tok_99v_tok_358v_tok_1018v_tok_862v_tok_779v_tok_62v_tok_835v_tok_25v_tok_254v_tok_254v_tok_677v_tok_73v_tok_143v_tok_696v_tok_696v_tok_321v_tok_879v_tok_23v_tok_224v_tok_523v_tok_23v_tok_835v_tok_835v_tok_835v_tok_395v_tok_59v_tok_257v_tok_819v_tok_472v_tok_835v_tok_835v_tok_408v_tok_339v_tok_835v_tok_835v_tok_475v_tok_339v_tok_428v_tok_982v_tok_869v_tok_270v_tok_435v_tok_283v_tok_804v_tok_976v_tok_875v_tok_598v_tok_353v_tok_860v_tok_409v_tok_411v_tok_601v_tok_650v_tok_495v_tok_62v_tok_835v_tok_835v_tok_141v_tok_948v_tok_82v_tok_414v_tok_658v_tok_321v_tok_224v_tok_321v_tok_931v_tok_3v_tok_99v_tok_8v_tok_220v_tok_775v_tok_739v_tok_870v_tok_830v_tok_739v_tok_830v_tok_695v_tok_695v_tok_704v_tok_208v_tok_860v_tok_1001v_tok_982v_tok_240v_tok_593v_tok_830v_tok_411v_tok_63v_tok_855v_tok_1017v_tok_835v_tok_835v_tok_430v_tok_339v_tok_339v_tok_339v_tok_254v_tok_254v_tok_38v_tok_677v_tok_73v_tok_868v_tok_598v_tok_563v_tok_890v_tok_598v_tok_224v_tok_598v_tok_676v_tok_860v_tok_635v_tok_310v_tok_208v_tok_224v_tok_676v_tok_491v_tok_321v_tok_699v_tok_136v_tok_432v_tok_1019v_tok_475v_tok_537v_tok_176v_tok_176v_tok_436v_tok_373v_tok_160v_tok_709v_tok_339v_tok_339v_tok_709v_tok_339v_tok_475v_tok_537v_tok_1017v_tok_835v_tok_475v_tok_430v_tok_835v_tok_835v_tok_855v_tok_339v_tok_676v_tok_567v_tok_903v_tok_846v_tok_8v_tok_377v_tok_634v_tok_556v_tok_771v_tok_771v_tok_771v_tok_422v_tok_411v_tok_411v_tok_74v_tok_378v_tok_914v_tok_378v_tok_1023v_tok_582v_tok_915v_tok_368v_tok_934v_tok_160v_tok_438v_tok_438v_tok_237v_tok_1017v_tok_133v_tok_133v_tok_479v_tok_479v_tok_388v_tok_151v_tok_940v_tok_465v_tok_906v_tok_407v_tok_808v_tok_70v_tok_208v_tok_176v_tok_537v_tok_676v_tok_723v_tok_813v_tok_358v_tok_593v_tok_830v_tok_612v_tok_699v_tok_136v_tok_1011v_tok_431v_tok_128v_tok_754v_tok_437v_tok_984v_tok_984v_tok_344v_tok_370v_tok_819v_tok_819v_tok_904v_tok_257v_tok_879v_tok_716v_tok_205v_tok_248v_tok_78v_tok_775v_tok_51v_tok_830v_tok_336v_tok_548v_tok_387v_tok_269v_tok_954v_tok_479v_tok_317v_tok_276v_tok_121v_tok_835v_tok_228v_tok_537v_tok_341v_tok_136v_tok_1008v_tok_984v_tok_931v_tok_949v_tok_723v_tok_954v_tok_820v_tok_269v_tok_532v_tok_716v_tok_556v_tok_688v_tok_556v_tok_903v_tok_288v_tok_309v_tok_556v_tok_392v_tok_216v_tok_958v_tok_699v_tok_835v_tok_103v_tok_176v_tok_408v_tok_408v_tok_339v_tok_339v_tok_904v_tok_559v_tok_535v_tok_141v_tok_960v_tok_908v_tok_361v_tok_400v_tok_141v_tok_1020v_tok_820v_tok_837v_tok_400v_tok_916v_tok_985v_tok_372v_tok_372v_tok_431v_tok_573v_tok_437v_tok_358v_tok_421v_tok_830v_tok_739v_tok_870v_tok_739v_tok_358v_tok_358v_tok_870v_tok_411v_tok_411v_tok_679v_tok_875v_tok_23v_tok_921v_tok_185v_tok_208v_tok_408v_tok_339v_tok_461v_tok_145v_tok_934v_tok_148v_tok_731v_tok_531v_tok_645v_tok_782v_tok_722v_tok_645v_tok_753v_tok_321v_tok_23v_tok_875v_tok_141v_tok_884v_tok_502v_tok_642v_tok_584v_tok_884v_tok_141v_tok_479v_tok_411v_tok_771v_tok_903v_tok_377v_tok_377v_tok_377v_tok_309v_tok_716v_tok_771v_tok_198v_tok_118v_tok_392v_tok_1018v_tok_1008v_tok_779v_tok_62v_tok_339v_tok_103v_tok_63v_tok_254v_tok_677v_tok_967v_tok_868v_tok_155v_tok_670v_tok_879v_tok_23v_tok_321v_tok_321v_tok_325v_tok_62v_tok_835v_tok_339v_tok_25v_tok_479v_tok_904v_tok_887v_tok_395v_tok_835v_tok_835v_tok_126v_tok_339v_tok_835v_tok_133v_tok_133v_tok_339v_tok_593v_tok_869v_tok_434v_tok_435v_tok_222v_tok_385v_tok_321v_tok_310v_tok_598v_tok_353v_tok_971v_tok_409v_tok_479v_tok_846v_tok_937v_tok_192v_tok_865v_tok_835v_tok_835v_tok_40v_tok_846v_tok_288v_tok_950v_tok_598v_tok_224v_tok_321v_tok_881v_tok_928v_tok_392v_tok_556v_tok_903v_tok_775v_tok_775v_tok_870v_tok_830v_tok_830v_tok_688v_tok_369v_tok_269v_tok_804v_tok_604v_tok_1001v_tok_495v_tok_813v_tok_830v_tok_593v_tok_51v_tok_141v_tok_887v_tok_780v_tok_835v_tok_835v_tok_1019v_tok_339v_tok_339v_tok_25v_tok_254v_tok_38v_tok_103v_tok_677v_tok_23v_tok_424v_tok_598v_tok_563v_tok_945v_tok_1001v_tok_224v_tok_871v_tok_598v_tok_676v_tok_676v_tok_676v_tok_875v_tok_860v_tok_676v_tok_151v_tok_321v_tok_699v_tok_491v_tok_699v_tok_25v_tok_835v_tok_677v_tok_176v_tok_798v_tok_373v_tok_373v_tok_160v_tok_463v_tok_339v_tok_339v_tok_463v_tok_339v_tok_475v_tok_395v_tok_1017v_tok_835v_tok_339</s>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfrl_outdir = 'train-0424-300000'\n",
    "agent.load(pfrl_outdir + '/best')\n",
    "actor.predict(observation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 3 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_3.wav\n",
      "Length of predicted_list: 658\n",
      "n_wins 861  seg_length 15  x.shape[1] 875\n",
      "x.shape torch.Size([1300, 1, 48, 15])  n_wins 861\n",
      "Reward: 2.451171875\n",
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 4 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_4.wav\n",
      "Length of predicted_list: 654\n",
      "n_wins 856  seg_length 15  x.shape[1] 870\n",
      "x.shape torch.Size([1300, 1, 48, 15])  n_wins 856\n",
      "Reward: 2.26953125\n",
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 5 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_5.wav\n",
      "Length of predicted_list: 650\n",
      "n_wins 851  seg_length 15  x.shape[1] 865\n",
      "x.shape torch.Size([1300, 1, 48, 15])  n_wins 851\n",
      "Reward: 2.224609375\n",
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 6 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_6.wav\n",
      "Length of predicted_list: 655\n",
      "n_wins 857  seg_length 15  x.shape[1] 871\n",
      "x.shape torch.Size([1300, 1, 48, 15])  n_wins 857\n",
      "Reward: 2.302734375\n",
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 7 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_7.wav\n",
      "Length of predicted_list: 652\n",
      "n_wins 239  seg_length 15  x.shape[1] 253\n",
      "x.shape torch.Size([1300, 1, 48, 15])  n_wins 239\n",
      "Reward: 2.61328125\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    ckpt = f'{i*50000}_checkpoint'\n",
    "    agent.load(pfrl_outdir + '/' + ckpt)\n",
    "    actor.predict(observation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- reset -----------------------------\n",
      "size_of_packed_input:  335\n",
      "Input IDs shape: torch.Size([1, 335])\n",
      "Episode 8 : audio saved to  /work/b0990106x/TextRL/output-predict/example_save_8.wav\n",
      "Length of predicted_list: 655\n",
      "n_wins 857  seg_length 15  x.shape[1] 871\n",
      "x.shape torch.Size([1300, 1, 48, 15])  n_wins 857\n",
      "Reward: 2.12890625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['v_tok_780v_tok_835v_tok_835v_tok_798v_tok_585v_tok_550v_tok_535v_tok_535v_tok_737v_tok_737v_tok_377v_tok_556v_tok_601v_tok_787v_tok_8v_tok_99v_tok_411v_tok_411v_tok_378v_tok_937v_tok_378v_tok_937v_tok_804v_tok_838v_tok_890v_tok_934v_tok_47v_tok_438v_tok_438v_tok_731v_tok_738v_tok_133v_tok_709v_tok_479v_tok_479v_tok_479v_tok_151v_tok_940v_tok_502v_tok_906v_tok_407v_tok_645v_tok_70v_tok_208v_tok_537v_tok_537v_tok_1022v_tok_681v_tok_723v_tok_747v_tok_593v_tok_804v_tok_681v_tok_879v_tok_136v_tok_967v_tok_233v_tok_431v_tok_754v_tok_421v_tok_182v_tok_182v_tok_651v_tok_879v_tok_887v_tok_819v_tok_904v_tok_904v_tok_887v_tok_309v_tok_880v_tok_396v_tok_754v_tok_775v_tok_997v_tok_222v_tok_336v_tok_548v_tok_841v_tok_269v_tok_479v_tok_479v_tok_940v_tok_23v_tok_56v_tok_738v_tok_835v_tok_395v_tok_206v_tok_779v_tok_531v_tok_862v_tok_931v_tok_306v_tok_203v_tok_755v_tok_369v_tok_6v_tok_466v_tok_716v_tok_948v_tok_82v_tok_575v_tok_288v_tok_556v_tok_903v_tok_556v_tok_392v_tok_796v_tok_751v_tok_835v_tok_103v_tok_25v_tok_408v_tok_835v_tok_835v_tok_339v_tok_339v_tok_395v_tok_250v_tok_706v_tok_317v_tok_479v_tok_800v_tok_960v_tok_141v_tok_479v_tok_908v_tok_801v_tok_327v_tok_937v_tok_559v_tok_708v_tok_372v_tok_372v_tok_573v_tok_437v_tok_437v_tok_421v_tok_203v_tok_739v_tok_830v_tok_739v_tok_358v_tok_830v_tok_248v_tok_411v_tok_411v_tok_112v_tok_321v_tok_23v_tok_23v_tok_185v_tok_971v_tok_62v_tok_339v_tok_461v_tok_488v_tok_934v_tok_148v_tok_373v_tok_561v_tok_681v_tok_760v_tok_531v_tok_612v_tok_699v_tok_23v_tok_967v_tok_457v_tok_790v_tok_154v_tok_906v_tok_465v_tok_502v_tok_884v_tok_479v_tok_246v_tok_820v_tok_601v_tok_309v_tok_716v_tok_314v_tok_377v_tok_309v_tok_309v_tok_556v_tok_118v_tok_99v_tok_358v_tok_1018v_tok_862v_tok_779v_tok_62v_tok_835v_tok_25v_tok_254v_tok_254v_tok_677v_tok_73v_tok_143v_tok_696v_tok_696v_tok_321v_tok_879v_tok_23v_tok_224v_tok_523v_tok_23v_tok_835v_tok_835v_tok_835v_tok_475v_tok_59v_tok_257v_tok_819v_tok_472v_tok_835v_tok_835v_tok_408v_tok_339v_tok_835v_tok_835v_tok_463v_tok_339v_tok_428v_tok_982v_tok_869v_tok_270v_tok_435v_tok_283v_tok_804v_tok_976v_tok_875v_tok_598v_tok_353v_tok_860v_tok_409v_tok_411v_tok_601v_tok_650v_tok_495v_tok_62v_tok_835v_tok_835v_tok_141v_tok_948v_tok_82v_tok_414v_tok_658v_tok_321v_tok_224v_tok_321v_tok_931v_tok_3v_tok_99v_tok_8v_tok_220v_tok_775v_tok_739v_tok_870v_tok_830v_tok_739v_tok_830v_tok_695v_tok_695v_tok_704v_tok_208v_tok_860v_tok_1001v_tok_982v_tok_240v_tok_593v_tok_830v_tok_411v_tok_63v_tok_855v_tok_1017v_tok_835v_tok_835v_tok_430v_tok_339v_tok_339v_tok_339v_tok_254v_tok_254v_tok_38v_tok_677v_tok_73v_tok_868v_tok_598v_tok_563v_tok_890v_tok_598v_tok_224v_tok_598v_tok_676v_tok_860v_tok_635v_tok_310v_tok_208v_tok_224v_tok_676v_tok_491v_tok_321v_tok_699v_tok_136v_tok_432v_tok_1019v_tok_475v_tok_537v_tok_176v_tok_176v_tok_436v_tok_373v_tok_160v_tok_709v_tok_339v_tok_339v_tok_835v_tok_339v_tok_475v_tok_537v_tok_1017v_tok_835v_tok_408v_tok_835v_tok_475v_tok_835v_tok_339v_tok_835v_tok_438v_tok_1022v_tok_550v_tok_535v_tok_869v_tok_737v_tok_737v_tok_737v_tok_556v_tok_601v_tok_99v_tok_8v_tok_99v_tok_479v_tok_411v_tok_378v_tok_874v_tok_378v_tok_937v_tok_765v_tok_838v_tok_890v_tok_349v_tok_47v_tok_438v_tok_488v_tok_731v_tok_738v_tok_106v_tok_709v_tok_479v_tok_803v_tok_479v_tok_151v_tok_533v_tok_502v_tok_906v_tok_804v_tok_645v_tok_70v_tok_753v_tok_537v_tok_537v_tok_872v_tok_681v_tok_723v_tok_358v_tok_593v_tok_804v_tok_431v_tok_879v_tok_136v_tok_979v_tok_233v_tok_431v_tok_233v_tok_421v_tok_182v_tok_203v_tok_651v_tok_879v_tok_935v_tok_819v_tok_904v_tok_370v_tok_887v_tok_309v_tok_434v_tok_396v_tok_754v_tok_880v_tok_997v_tok_222v_tok_997v_tok_548v_tok_841v_tok_479v_tok_479v_tok_141v_tok_317v_tok_23v_tok_56v_tok_1017v_tok_835v_tok_395v_tok_202v_tok_779v_tok_531v_tok_858v_tok_931v_tok_306v_tok_585v_tok_755v_tok_369v_tok_288v_tok_466v_tok_716v_tok_288v_tok_82v_tok_575v_tok_348v_tok_556v_tok_903v_tok_634v_tok_392v_tok_796v_tok_967v_tok_835v_tok_103v_tok_103v_tok_738v_tok_835v_tok_835v_tok_133v_tok_339v_tok_395v_tok_852v_tok_706v_tok_317v_tok_141v_tok_800v_tok_960v_tok_908v_tok_479v_tok_908v_tok_642v_tok_327v_tok_937v_tok_907v_tok_708v_tok_372v_tok_1008v_tok_573v_tok_437v_tok_585v_tok_203v_tok_203v_tok_739v_tok_739v_tok_755v_tok_358v_tok_830v_tok_411v_tok_411v_tok_411v_tok_683v_tok_321v_tok_23v_tok_1022v_tok_185v_tok_971v_tok_835v_tok_339v_tok_461v_tok_438v_tok_934v_tok_373v_tok_373v_tok_561v_tok_588v_tok_760v_tok_804v_tok_982v_tok_699v_tok_23v_tok_255v_tok_457v_tok_790v_tok_361v_tok_906v_tok_465v_tok_776v_tok_884v_tok_479v_tok_327v_tok_820v_tok_601v_tok_55v_tok_716v_tok_314v_tok_99v_tok_309v_tok_309v_tok_377v_tok_118v_tok_99v_tok_392v_tok_1018v_tok_862v_tok_604v_tok_62v_tok_835v_tok_395v_tok_254v_tok_254v_tok_237v_tok_73v_tok_143v_tok_875v_tok_696v_tok_321v_tok_321v_tok_23v_tok_224v_tok_1022v_tok_23v_tok_835v_tok_408v_tok_738v_tok_339v_tok_59v_tok_257v_tok_887v_tok_472v_tok_835v_tok_1017v_tok_835v_tok_339v_tok_133v_tok_835v_tok_339v_tok_395v_tok_428v_tok_982v_tok_989v_tok_270v_tok_435v_tok_965v_tok_804v_tok_976v_tok_1001v_tok_598v_tok_353v_tok_321v_tok_409v_tok_411v_tok_820v_tok_650v_tok_495v_tok_835v_tok_835v_tok_395v_tok_141v_tok_948v_tok_340v_tok_414v_tok_658v_tok_871v_tok_224v_tok_321v_tok_143v_tok_3v_tok_99v_tok_248v_tok_220v_tok_775v_tok_146v_tok_870v_tok_830v_tok_162v_tok_830v_tok_695v_tok_501v_tok_704v_tok_208v_tok_1022v_tok_1001v_tok_495v_tok_240v_tok_593v_tok_951v_tok_411v_tok_63v_tok_106v_tok_1017v_tok_835v_tok_475v_tok_430v_tok_339v_tok_835v_tok_395v_tok_331v_tok_254v_tok_38v_tok_666v_tok_73v_tok_868v_tok_862v_tok_563v_tok_890v_tok_1001v_tok_224v_tok_598v_tok_151v_tok_860v_tok_635v_tok_976v_tok_208v_tok_224v_tok_731v_tok_491v_tok_321v_tok_310v_tok_136v_tok_432v_tok_834v_tok_475v_tok_537v_tok_373v_tok_176v_tok_436v_tok_676v_tok_160v_tok_709v_tok_709v_tok_339v_tok_855v_tok_339v_tok_475v_tok_25v_tok_1017v_tok_835v_tok_62</s>']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = '300000_finish'\n",
    "agent.load(pfrl_outdir + '/' + ckpt)\n",
    "actor.predict(observation_list[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c6c77b12b02a1c2aaa91a9fb9cc35bb3c4bbfb7b716f83ac7b2b57ffb1247cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
