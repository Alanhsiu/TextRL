{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5gZSqIG1ah"
   },
   "source": [
    "# Controllable generation via RL about text-guided voice conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# load the model\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "ar_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "# define the path\n",
    "base_path = \"/work/b0990106x/TextRL\"\n",
    "agent_input_dir = f\"{base_path}/data-encodec\"\n",
    "agent_output_dir = f\"{base_path}/output/{ts}\"\n",
    "env_input_dir = agent_output_dir\n",
    "env_output_dir = agent_input_dir\n",
    "\n",
    "if not os.path.exists(agent_output_dir):\n",
    "    os.makedirs(agent_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = load_from_disk(agent_input_dir)\n",
    "\n",
    "all_src_encodec_layers = []\n",
    "all_src_encodec = []\n",
    "all_instruction = []\n",
    "# all_instruction_ids = []\n",
    "\n",
    "layer_len = 8\n",
    "data_len = 3\n",
    "# data_len = len(dataset)\n",
    "print(\"data_len:\", data_len)\n",
    "\n",
    "for i in range(layer_len):\n",
    "    all_src_encodec_layers.append(dataset[f\"src_encodec_{i}\"])\n",
    "\n",
    "for i in range(data_len):\n",
    "    src_encodec = []\n",
    "    for j in range(layer_len):\n",
    "        src_encodec.append(all_src_encodec_layers[j][i])\n",
    "    all_src_encodec.append(src_encodec)\n",
    "\n",
    "    all_instruction.append(dataset[\"instruction\"][i])\n",
    "    # all_instruction_ids.append(ar_tokenizer(all_instruction[i])[\"input_ids\"][1 : -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import textrl\n",
    "\n",
    "reload(textrl)\n",
    "\n",
    "from textrl import TextRLEnv, TextRLActor\n",
    "from NISQA.nisqa.NISQA_model import nisqaModel\n",
    "\n",
    "\n",
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, _, predicted_list, finish):\n",
    "        reward = 0\n",
    "        if finish or len(predicted_list) >= self.env_max_length:\n",
    "            try:\n",
    "                args_nisqa = {\n",
    "                    \"mode\": \"predict_file\",\n",
    "                    \"pretrained_model\": f\"{base_path}/NISQA/weights/nisqa.tar\",\n",
    "                    \"deg\": f\"{base_path}/output/{ts}/example.wav\",\n",
    "                    \"data_dir\": None,\n",
    "                    \"output_dir\": f\"{base_path}/NISQA/result/\",\n",
    "                    \"csv_file\": None,\n",
    "                    \"csv_deg\": None,\n",
    "                    \"num_workers\": 0,\n",
    "                    \"bs\": 1,\n",
    "                    \"ms_channel\": None,\n",
    "                }\n",
    "                args_nisqa[\"tr_bs_val\"] = args_nisqa[\"bs\"]\n",
    "                args_nisqa[\"tr_num_workers\"] = args_nisqa[\"num_workers\"]\n",
    "\n",
    "                nisqa = nisqaModel(args_nisqa)\n",
    "                prediction = nisqa.predict()\n",
    "                reward = float(prediction[\"mos_pred\"].iloc[0])\n",
    "                print(\n",
    "                    \"Length of predicted_list:\",\n",
    "                    len(predicted_list[0]),\n",
    "                    \", Reward:\",\n",
    "                    reward,\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "                reward = 0\n",
    "\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_list = []\n",
    "for i in range(3):\n",
    "    observation_list.append(\n",
    "        {\n",
    "            \"input\": \"\",\n",
    "            \"src_encodec\": all_src_encodec[i],\n",
    "            \"instruction\": all_instruction[i],\n",
    "        }\n",
    "    )\n",
    "    print(\"src_encodec:\", observation_list[i][\"src_encodec\"][0])\n",
    "    print(\"instruction:\", all_instruction[i])\n",
    "\n",
    "# for i in range(data_len):\n",
    "#     observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[i], 'instruction': all_instruction[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"observation_list:\", observation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "args_predict = SimpleNamespace(\n",
    "    output_path=f\"{base_path}/output/{ts}/example.wav\", seed=0, device=\"cuda\"\n",
    ")\n",
    "\n",
    "env = MyRLEnv(\n",
    "    ar_model,\n",
    "    ar_tokenizer,\n",
    "    nar_model,\n",
    "    nar_tokenizer,\n",
    "    args_predict,\n",
    "    observation_input=observation_list,\n",
    "    compare_sample=1,\n",
    ")\n",
    "actor = TextRLActor(env, ar_model, ar_tokenizer, ts)\n",
    "agent = actor.agent_ppo(update_interval=1500, minibatch_size=2000, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "output_log_path = f\"log/log_{ts}.log\"\n",
    "output_file_path = f\"log/output_{ts}.txt\"\n",
    "\n",
    "if not os.path.exists(\"log\"):\n",
    "    os.makedirs(\"log\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "handlers = logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "file_handler = logging.FileHandler(output_log_path)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "# class StreamToLogger(object):\n",
    "#     def __init__(self, logger, log_level):\n",
    "#         self.logger = logger\n",
    "#         self.log_level = log_level\n",
    "#         self.linebuf = \"\"\n",
    "\n",
    "#     def write(self, buf):\n",
    "#         for line in buf.rstrip().splitlines():\n",
    "#             self.logger.log(self.log_level, line.rstrip())\n",
    "\n",
    "#     def flush(self):\n",
    "#         pass\n",
    "\n",
    "\n",
    "# sys.stdout = StreamToLogger(logger, logging.INFO)\n",
    "# sys.stderr = StreamToLogger(logger, logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBysk9MiHR2D",
    "outputId": "4086dcd7-6d19-44bc-e1b0-fa764f873301",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pfrl\n",
    "\n",
    "start_time = time.time()\n",
    "pfrl_outdir = f\"ckpt/train_{ts}\"\n",
    "\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = f\n",
    "    pfrl.experiments.train_agent_with_evaluation(\n",
    "        agent,\n",
    "        env,\n",
    "        steps=10000,\n",
    "        eval_n_steps=None,\n",
    "        eval_n_episodes=5,\n",
    "        train_max_episode_len=1000,\n",
    "        eval_interval=1000,\n",
    "        outdir=pfrl_outdir,\n",
    "        logger=logger,\n",
    "        use_tensorboard=True,\n",
    "        checkpoint_freq=1000,\n",
    "    )\n",
    "    sys.stdout = original_stdout\n",
    "    \n",
    "print(\"Output has been written to\", output_file_path)\n",
    "print(\"used time: \", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpAwe42ES-5w",
    "outputId": "bb12c0d2-1916-4076-8f98-b20d2a2e4e57"
   },
   "outputs": [],
   "source": [
    "agent.load(pfrl_outdir + \"/best\")\n",
    "actor.predict(observation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_pickle\n",
    "# ts = \"0430-0955\"\n",
    "for i in range(10):\n",
    "    pickle_file = f\"replay_buffer_update_{i}.pkl\"\n",
    "    pickle_data = read_pickle.load_pickle(file_path = f'{base_path}/replay_buffer/{ts}/{pickle_file}')\n",
    "    length_of_pickle_data = len(pickle_data[0])\n",
    "    print(f\"length of {pickle_file}: {length_of_pickle_data}\") \n",
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c6c77b12b02a1c2aaa91a9fb9cc35bb3c4bbfb7b716f83ac7b2b57ffb1247cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
