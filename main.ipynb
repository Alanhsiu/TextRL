{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pfrl@ git+https://github.com/voidful/pfrl.git\n",
      "  Cloning https://github.com/voidful/pfrl.git to /tmp/pip-install-cwx7ldq_/pfrl_1c304f8bf4ea4b17b3dbc66e8850f7a2\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/voidful/pfrl.git /tmp/pip-install-cwx7ldq_/pfrl_1c304f8bf4ea4b17b3dbc66e8850f7a2\n",
      "  Resolved https://github.com/voidful/pfrl.git to commit bd679022d91902a3c88066d2646ad69b30d5684a\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (2.1.1)\n",
      "Requirement already satisfied: gym>=0.9.7 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/u9655801/.local/lib/python3.11/site-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (1.25.2)\n",
      "Requirement already satisfied: pillow in /home/u9655801/miniconda3/lib/python3.11/site-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/u9655801/miniconda3/lib/python3.11/site-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (3.12.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from gym>=0.9.7->pfrl@ git+https://github.com/voidful/pfrl.git) (0.0.8)\n",
      "Requirement already satisfied: typing-extensions in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (1.12)\n",
      "Requirement already satisfied: networkx in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/u9655801/.local/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from sympy->torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: textrl==0.2.15 in /home/u9655801/miniconda3/lib/python3.11/site-packages (0.2.15)\n",
      "Requirement already satisfied: gym in /home/u9655801/miniconda3/lib/python3.11/site-packages (from textrl==0.2.15) (0.26.2)\n",
      "Requirement already satisfied: transformers in /home/u9655801/miniconda3/lib/python3.11/site-packages (from textrl==0.2.15) (4.34.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/u9655801/.local/lib/python3.11/site-packages (from gym->textrl==0.2.15) (1.25.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from gym->textrl==0.2.15) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from gym->textrl==0.2.15) (0.0.8)\n",
      "Requirement already satisfied: filelock in /home/u9655801/miniconda3/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/u9655801/.local/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u9655801/.local/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/u9655801/miniconda3/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/u9655801/.local/lib/python3.11/site-packages (from transformers->textrl==0.2.15) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /home/u9655801/.local/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->textrl==0.2.15) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->textrl==0.2.15) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from requests->transformers->textrl==0.2.15) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from requests->transformers->textrl==0.2.15) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from requests->transformers->textrl==0.2.15) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/u9655801/miniconda3/lib/python3.11/site-packages (from requests->transformers->textrl==0.2.15) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pfrl@git+https://github.com/voidful/pfrl.git\n",
    "!pip install textrl==0.2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/voidful/pfrl.git\n",
      "  Cloning https://github.com/voidful/pfrl.git to /tmp/pip-req-build-z3hwhgkx\n",
      "  Running command git clone --filter=blob:none -q https://github.com/voidful/pfrl.git /tmp/pip-req-build-z3hwhgkx\n",
      "  Resolved https://github.com/voidful/pfrl.git to commit bd679022d91902a3c88066d2646ad69b30d5684a\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from pfrl==0.4.0) (1.10.1)\n",
      "Collecting gym>=0.9.7\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     |████████████████████████████████| 721 kB 1.1 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from pfrl==0.4.0) (1.20.3)\n",
      "Requirement already satisfied: pillow in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from pfrl==0.4.0) (8.4.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym>=0.9.7->pfrl==0.4.0) (7.0.1)\n",
      "Requirement already satisfied: typing_extensions in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from torch>=1.3.0->pfrl==0.4.0) (4.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym>=0.9.7->pfrl==0.4.0) (3.17.0)\n",
      "Building wheels for collected packages: pfrl, gym\n",
      "  Building wheel for pfrl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pfrl: filename=pfrl-0.4.0-py3-none-any.whl size=155504 sha256=e2e425d15f324ee0e658bd425faf071cd578b72e0a90a8386a9db740a8d34541\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wr8k154h/wheels/4e/7a/0d/6d90ea0eecefee2bcf373177932fd54e84b41ef5190472e2db\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827638 sha256=7a521ac544af9615b51a5accc12fd4bd76f7b4a2ece38d78c27bd36b1bc55ba0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-wr8k154h/wheels/af/2b/30/5e78b8b9599f2a2286a582b8da80594f654bf0e18d825a4405\n",
      "Successfully built pfrl gym\n",
      "Installing collected packages: gym-notices, cloudpickle, gym, filelock, pfrl\n",
      "Successfully installed cloudpickle-3.0.0 filelock-3.13.1 gym-0.26.2 gym-notices-0.0.8 pfrl-0.4.0\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting textrl==0.2.15\n",
      "  Downloading textrl-0.2.15-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: gym in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from textrl==0.2.15) (0.26.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "     |████████████████████████████████| 8.4 MB 1.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym->textrl==0.2.15) (1.20.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym->textrl==0.2.15) (7.0.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym->textrl==0.2.15) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym->textrl==0.2.15) (0.0.8)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "     |████████████████████████████████| 330 kB 69.4 MB/s            \n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "     |████████████████████████████████| 773 kB 51.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (4.62.3)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 50.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (23.2)\n",
      "Requirement already satisfied: requests in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "     |████████████████████████████████| 3.6 MB 49.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (3.13.1)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "     |████████████████████████████████| 170 kB 11.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers->textrl==0.2.15) (4.9.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym->textrl==0.2.15) (3.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from requests->transformers->textrl==0.2.15) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from requests->transformers->textrl==0.2.15) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from requests->transformers->textrl==0.2.15) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/u9655801/miniconda3/envs/textrl/lib/python3.9/site-packages (from requests->transformers->textrl==0.2.15) (3.3.2)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, safetensors, regex, transformers, textrl\n",
      "Successfully installed fsspec-2024.2.0 huggingface-hub-0.20.3 regex-2023.12.25 safetensors-0.4.2 textrl-0.2.15 tokenizers-0.15.2 transformers-4.37.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/voidful/pfrl.git\n",
    "!{sys.executable} -m pip install textrl==0.2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u9655801/miniconda3/envs/textrl/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u9655801/miniconda3/bin/pip\r\n"
     ]
    }
   ],
   "source": [
    "!which pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pfrl\n",
    "from textrl import TextRLEnv,TextRLActor\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelWithLMHead\n",
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')\n",
    "from NISQA.nisqa.NISQA_model import nisqaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(59481, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(59481, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(59481, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=59481, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\")\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline('sentiment-analysis',model=\"cardiffnlp/twitter-roberta-base-sentiment\",tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment\",device=0,return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_logger = logging.getLogger('transformers')\n",
    "transformers_logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment(\"dogecoin is bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment(\"dogecoin is bad\")[0][0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRLEnv(TextRLEnv):\n",
    "    def __init__(self, model, tokenizer, device=\"cuda\", observation_input=[], max_length=100, compare_sample=2):\n",
    "        super().__init__(model, tokenizer, observation_input, max_length, compare_sample)\n",
    "        self.device = torch.device(device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.observation_input = observation_input\n",
    "        \n",
    "        \n",
    "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
    "        args = {\n",
    "            'mode': 'predict_file',  # For example, 'predict_file', 'predict_dir', or 'predict_csv'\n",
    "            'pretrained_model': 'weights/nisqa.tar',  # Name of the pretrained model file\n",
    "            'deg': '/home/u9655801/hw/TextRL/NISQA/test.wav',  # Path to the speech file if mode is predict_file\n",
    "            'data_dir': None,  # Folder with speech files if mode is predict_dir\n",
    "            'output_dir': '/home/u9655801/hw/TextRL/NISQA/result',  # Folder to output results.csv\n",
    "            'csv_file': None,  # Name of the csv file if mode is predict_csv\n",
    "            'csv_deg': None,  # Column name in csv with file names/paths if mode is predict_csv\n",
    "            'num_workers': 0,  # Number of workers for PyTorch's DataLoader\n",
    "            'bs': 1,  # Batch size for predicting\n",
    "            'ms_channel': None,  # Audio channel in case of a stereo file, if needed\n",
    "        }\n",
    "\n",
    "        if args['mode'] == 'predict_file':\n",
    "            if args['deg'] is None:\n",
    "                raise ValueError('--deg argument with path to input file needed')\n",
    "        elif args['mode'] == 'predict_dir':\n",
    "            if args['data_dir'] is None:\n",
    "                raise ValueError('--data_dir argument with folder with input files needed')\n",
    "        elif args['mode'] == 'predict_csv':\n",
    "            if args['csv_file'] is None:\n",
    "                raise ValueError('--csv_file argument with csv file name needed')\n",
    "            if args['csv_deg'] is None:\n",
    "                raise ValueError('--csv_deg argument with csv column name of the filenames needed')\n",
    "            if args['data_dir'] is None:\n",
    "                args['data_dir'] = ''\n",
    "        else:\n",
    "                raise NotImplementedError('--mode given not available')\n",
    "\n",
    "        args['tr_bs_val'] = args['bs']\n",
    "        args['tr_num_workers'] = args['num_workers']\n",
    "        \n",
    "        \n",
    "        nisqa = nisqaModel(args)\n",
    "        prediction = nisqa.predict()\n",
    "        reward = int(prediction['mos_pred'].iloc[0])\n",
    "        return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        predicted, finish, predicted_str = self.predict(vocab_id=action)\n",
    "        reward = self.get_reward(self.input_item, predicted, finish)\n",
    "        # Assuming `action` is an index representing a choice of instruction or modification\n",
    "\n",
    "        # Prepare the model input based on the chosen action\n",
    "        # This involves selecting the instruction and possibly modifying voice features\n",
    "        instruction, transcription, src_encodec_ids = self.prepare_input(action)\n",
    "\n",
    "        # Generate voice output using the model\n",
    "        # For simplicity, we're directly using a method that might encapsulate the model interaction\n",
    "        layer_list = self.generate_voice(instruction, transcription, src_encodec_ids)\n",
    "\n",
    "        # Convert model output to audio and evaluate it to calculate the reward\n",
    "        encodec_code = convert_to_encode_code(self.tokenizer, layer_list)\n",
    "        audio = synthesize_audio(encodec_code, self.device)\n",
    "        reward = self.evaluate_audio(audio)  # This would be an external or predefined method\n",
    "\n",
    "        # Check if the episode is done based on your criteria\n",
    "        done = self.check_done()\n",
    "\n",
    "        # Optionally update the environment state here\n",
    "\n",
    "        return self.get_observation(), reward, done, {}\n",
    "    \n",
    "    def predict(self, vocab_id):\n",
    "        predicted_list = {}\n",
    "        predicted_list_end = {}\n",
    "        with torch.inference_mode():\n",
    "            for i, (v_id, predicted, predicted_end) in enumerate(zip(vocab_id, self.predicted, self.predicted_end)):\n",
    "                predicted_list_end[i] = False\n",
    "                if not predicted_end:\n",
    "                    pred_word = self.actions[v_id]\n",
    "                    if pred_word in self.gen_stop_toks \\\n",
    "                            or len(pred_word) < 1 \\\n",
    "                            or len(predicted) > self.env_max_length:\n",
    "                        predicted_list_end[i] = True\n",
    "                        predicted_list[i] = [pred_word]\n",
    "                    else:\n",
    "                        predicted_list[i] = [pred_word]\n",
    "                else:\n",
    "                    predicted_list_end[i] = True\n",
    "                    predicted_list[i] = ['']\n",
    "\n",
    "            for i, (l, e) in enumerate(zip(predicted_list.values(), predicted_list_end.values())):\n",
    "                self.predicted[i] = self.predicted[i] + l\n",
    "                self.predicted_end[i] = e\n",
    "\n",
    "            return self.predicted, all(self.predicted_end), [self.tokenizer.convert_tokens_to_string(i) for i in\n",
    "                                                             self.predicted]\n",
    "    def reset(self):\n",
    "        # Reset or initialize the environment state\n",
    "        # This could involve loading or selecting a new dataset entry for instructions and voice features\n",
    "\n",
    "        self.current_instruction, self.current_transcription, self.current_src_encodec_ids = self.select_new_instruction()\n",
    "\n",
    "        # Prepare the initial observation based on the new instruction\n",
    "        # This step depends on how you define an observation in your environment\n",
    "        initial_observation = self.prepare_observation(self.current_instruction, self.current_transcription)\n",
    "\n",
    "        return initial_observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = [{}]\n",
    "input_audio = \"\"\n",
    "\n",
    "observaton_list = [{'input':'i think dogecoin is'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MyRLEnv(model, tokenizer, observation_input=observaton_list, compare_sample=1)\n",
    "actor = TextRLActor(env,model,tokenizer,optimizer='adamw',\n",
    "                    temperature=0.8,\n",
    "                    top_k=100,\n",
    "                    top_p=0.85,)\n",
    "agent = actor.agent_ppo(update_interval=50, minibatch_size=3, epochs=10,lr=3e-4)\n",
    "print(actor.predict(observaton_list[0]))\n",
    "\n",
    "pfrl.experiments.train_agent_with_evaluation(\n",
    "    agent,\n",
    "    env,\n",
    "    steps=3000,\n",
    "    eval_n_steps=None,\n",
    "    eval_n_episodes=1,       \n",
    "    train_max_episode_len=100,  \n",
    "    eval_interval=10,\n",
    "    outdir='checkpoint', \n",
    ")\n",
    "agent.load(\"./checkpoint/best\")\n",
    "print(actor.predict(observaton_list[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextRL",
   "language": "python",
   "name": "textrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
