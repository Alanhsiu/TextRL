{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5gZSqIG1ah"
   },
   "source": [
    "# Controllable generation via RL about text-guided voice conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(59481, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(59481, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(59481, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=59481, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# load the model\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "ar_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 0509-0100\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "# define the path\n",
    "base_path = \"/work/b0990106x/TextRL\"\n",
    "agent_input_dir = f\"{base_path}/data-encodec\"\n",
    "agent_output_dir = f\"{base_path}/output/{ts}\"\n",
    "env_input_dir = agent_output_dir\n",
    "env_output_dir = agent_input_dir\n",
    "\n",
    "if not os.path.exists(agent_output_dir):\n",
    "    os.makedirs(agent_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = load_from_disk(agent_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_len: 3\n"
     ]
    }
   ],
   "source": [
    "all_src_encodec_layers = []\n",
    "all_src_encodec = []\n",
    "all_instruction = []\n",
    "# all_instruction_ids = []\n",
    "\n",
    "layer_len = 8\n",
    "data_len = 3\n",
    "# data_len = len(dataset)\n",
    "print(\"data_len:\", data_len)\n",
    "\n",
    "for i in range(layer_len):\n",
    "    all_src_encodec_layers.append(dataset[f\"src_encodec_{i}\"])\n",
    "\n",
    "for i in range(data_len):\n",
    "    src_encodec = []\n",
    "    for j in range(layer_len):\n",
    "        src_encodec.append(all_src_encodec_layers[j][i])\n",
    "    all_src_encodec.append(src_encodec)\n",
    "\n",
    "    all_instruction.append(dataset[\"instruction\"][i])\n",
    "    # all_instruction_ids.append(ar_tokenizer(all_instruction[i])[\"input_ids\"][1 : -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_encodec_0 len: 327\n",
      "src_encodec_1 len: 336\n",
      "src_encodec_2 len: 131\n"
     ]
    }
   ],
   "source": [
    "# print the length of all src encodec\n",
    "for i in range(data_len):\n",
    "    print(f\"src_encodec_{i} len:\", len(all_src_encodec[i][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 0509-0100\n"
     ]
    }
   ],
   "source": [
    "# redefine the path (one can run the code from here when the model is already loaded)\n",
    "now = datetime.now()\n",
    "ts = now.strftime(\"%m%d-%H%M\")\n",
    "print(\"timestamp:\", ts)\n",
    "\n",
    "agent_output_dir = f\"{base_path}/output/{ts}\"\n",
    "env_input_dir = agent_output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import textrl\n",
    "reload(textrl)\n",
    "\n",
    "from textrl import TextRLEnv, TextRLActor\n",
    "from NISQA.nisqa.NISQA_model import nisqaModel\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/work/b0990106x/TextRL/vc\") \n",
    "from vc.trainer_encodec_vc_inference import get_ar_prediction_v2\n",
    "\n",
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, _, predicted_list, finish):\n",
    "        reward = 0\n",
    "        if finish or len(predicted_list[0]) >= self.env_max_length:\n",
    "        # if finish or len(predicted_list) >= self.env_max_length:\n",
    "            print(\"Length of predicted_list:\", len(predicted_list))\n",
    "            print(\"predicted_list:\", predicted_list)\n",
    "            reward = len(predicted_list[0])\n",
    "            # try:\n",
    "            #     predicted_tokens = predicted_list[0][1:-1]\n",
    "            #     predicted_ids = self.tokenizer.convert_tokens_to_ids([f\"{u}\" for u in predicted_tokens])\n",
    "            #     # print(\"predicted_ids:\", predicted_ids)\n",
    "\n",
    "            #     decode_ar = get_ar_prediction_v2(\n",
    "            #         self.args_predict,\n",
    "            #         predicted_ids,\n",
    "            #         self.nar_model,\n",
    "            #         self.tokenizer,\n",
    "            #         self.nar_tokenizer,\n",
    "            #         self.single_src_encodec,\n",
    "            #         self.single_instruction,\n",
    "            #         self.episode_counter,\n",
    "            #     )\n",
    "            #     # print(\"decode_ar:\", decode_ar)\n",
    "                \n",
    "            #     # use nisqa to get the reward\n",
    "            #     args_nisqa = {\n",
    "            #         \"mode\": \"predict_file\",\n",
    "            #         \"pretrained_model\": f\"{base_path}/NISQA/weights/nisqa.tar\",\n",
    "            #         \"deg\": f\"{base_path}/output/{ts}/example.wav\",\n",
    "            #         \"data_dir\": None,\n",
    "            #         \"output_dir\": f\"{base_path}/NISQA/result/\",\n",
    "            #         \"csv_file\": None,\n",
    "            #         \"csv_deg\": None,\n",
    "            #         \"num_workers\": 0,\n",
    "            #         \"bs\": 1,\n",
    "            #         \"ms_channel\": None,\n",
    "            #     }\n",
    "            #     args_nisqa[\"tr_bs_val\"] = args_nisqa[\"bs\"]\n",
    "            #     args_nisqa[\"tr_num_workers\"] = args_nisqa[\"num_workers\"]\n",
    "\n",
    "            #     nisqa = nisqaModel(args_nisqa)\n",
    "            #     prediction = nisqa.predict()\n",
    "            #     reward = float(prediction[\"mos_pred\"].iloc[0])*10\n",
    "            #     # reward = float(prediction[\"mos_pred\"].iloc[0])-3.0\n",
    "            #     print(\n",
    "            #         \"Length of predicted_list:\",\n",
    "            #         len(predicted_list[0]),\n",
    "            #         \", Reward:\",\n",
    "            #         reward,\n",
    "            #     )\n",
    "\n",
    "            # except Exception as e:\n",
    "            #     print(\"Error:\", e)\n",
    "            #     reward = 0\n",
    "\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_list: [{'input': '', 'src_encodec': [[835, 339, 999, 629, 604, 462, 314, 600, 846, 562, 846, 358, 984, 393, 182, 453, 584, 535, 407, 1021, 701, 843, 945, 495, 563, 495, 495, 727, 317, 604, 475, 835, 835, 835, 339, 475, 339, 123, 254, 103, 561, 858, 646, 755, 375, 548, 435, 233, 323, 395, 819, 475, 339, 835, 779, 257, 339, 341, 170, 38, 38, 103, 408, 62, 141, 731, 73, 651, 143, 875, 321, 310, 310, 972, 679, 582, 808, 813, 808, 291, 722, 982, 627, 192, 764, 531, 291, 466, 567, 601, 771, 112, 688, 348, 793, 793, 11, 192, 23, 983, 1022, 23, 73, 73, 276, 537, 103, 53, 148, 148, 148, 463, 176, 148, 463, 463, 463, 463, 463, 463, 463, 433, 25, 472, 257, 228, 395, 133, 395, 475, 126], [646, 841, 168, 1023, 277, 820, 278, 215, 58, 592, 607, 607, 349, 346, 504, 632, 482, 14, 968, 588, 529, 904, 662, 662, 602, 1013, 662, 386, 617, 870, 648, 1023, 277, 277, 913, 200, 1007, 503, 807, 144, 132, 558, 984, 164, 610, 66, 830, 925, 744, 129, 87, 648, 391, 646, 424, 700, 646, 713, 702, 443, 4, 43, 648, 747, 335, 630, 460, 342, 462, 303, 969, 229, 386, 984, 820, 955, 654, 486, 632, 655, 632, 893, 355, 537, 459, 754, 303, 214, 529, 365, 879, 199, 946, 303, 593, 593, 593, 889, 94, 320, 269, 161, 102, 8, 363, 974, 43, 549, 973, 961, 973, 200, 857, 993, 200, 200, 200, 200, 200, 772, 133, 1023, 516, 92, 87, 837, 765, 700, 601, 571, 200], [937, 752, 989, 196, 852, 310, 498, 380, 650, 354, 648, 677, 677, 1001, 750, 737, 148, 68, 905, 613, 977, 598, 311, 901, 803, 810, 463, 425, 45, 471, 829, 423, 821, 937, 653, 936, 36, 217, 68, 959, 216, 516, 80, 516, 128, 614, 901, 360, 448, 898, 626, 758, 821, 937, 653, 228, 653, 620, 189, 10, 841, 870, 593, 678, 646, 1021, 454, 825, 743, 753, 618, 938, 675, 286, 831, 110, 96, 835, 648, 916, 519, 663, 977, 38, 660, 753, 932, 684, 192, 545, 962, 323, 143, 748, 545, 545, 545, 310, 545, 475, 442, 798, 981, 870, 843, 602, 918, 326, 893, 590, 555, 937, 934, 1013, 934, 188, 188, 813, 730, 653, 1019, 541, 918, 1019, 345, 253, 989, 829, 989, 819, 821], [1022, 762, 835, 651, 854, 446, 629, 1001, 796, 216, 489, 370, 657, 319, 361, 203, 177, 660, 106, 143, 177, 740, 854, 388, 212, 920, 920, 516, 62, 222, 594, 686, 215, 215, 741, 739, 239, 831, 388, 1002, 1002, 612, 602, 584, 256, 986, 986, 687, 624, 874, 1022, 739, 916, 916, 651, 762, 741, 874, 761, 940, 588, 239, 211, 215, 239, 574, 239, 694, 935, 528, 497, 749, 674, 23, 66, 823, 876, 379, 577, 971, 532, 856, 577, 590, 757, 344, 23, 608, 308, 786, 438, 246, 967, 502, 320, 944, 206, 535, 679, 597, 699, 125, 793, 991, 734, 866, 940, 212, 443, 443, 1001, 721, 885, 919, 885, 398, 727, 443, 961, 940, 983, 823, 242, 675, 255, 651, 919, 215, 961, 838, 1022], [528, 222, 904, 375, 885, 186, 427, 284, 95, 559, 225, 368, 737, 500, 698, 728, 122, 689, 566, 138, 946, 363, 958, 637, 163, 270, 949, 422, 430, 875, 809, 89, 505, 375, 222, 714, 407, 797, 435, 247, 142, 700, 242, 800, 860, 880, 867, 428, 660, 561, 919, 435, 336, 900, 885, 736, 448, 167, 247, 203, 433, 89, 683, 190, 195, 38, 439, 877, 100, 967, 211, 899, 167, 556, 39, 932, 426, 228, 728, 350, 961, 232, 984, 744, 379, 247, 924, 193, 156, 368, 980, 1017, 332, 824, 814, 654, 208, 869, 435, 456, 140, 958, 586, 944, 357, 357, 907, 472, 49, 190, 222, 694, 382, 379, 983, 373, 379, 540, 505, 540, 606, 373, 944, 903, 1007, 904, 604, 736, 882, 885, 884], [1011, 140, 140, 435, 692, 244, 5, 942, 125, 95, 898, 816, 159, 105, 345, 587, 241, 813, 419, 24, 830, 247, 991, 630, 54, 416, 583, 917, 200, 147, 781, 315, 692, 41, 41, 982, 881, 13, 124, 255, 615, 694, 672, 291, 574, 42, 691, 423, 35, 549, 478, 692, 386, 1011, 1011, 701, 881, 931, 382, 946, 96, 303, 692, 412, 324, 603, 186, 196, 640, 262, 10, 850, 763, 219, 692, 363, 363, 339, 875, 218, 989, 228, 476, 368, 423, 399, 510, 198, 526, 358, 667, 27, 613, 974, 604, 122, 834, 801, 657, 282, 931, 975, 562, 650, 567, 349, 1005, 825, 609, 632, 851, 935, 315, 917, 96, 995, 477, 530, 334, 23, 390, 929, 644, 692, 505, 903, 185, 982, 1005, 701, 140], [1002, 748, 1015, 764, 983, 330, 1, 102, 399, 330, 656, 392, 890, 560, 335, 44, 662, 684, 442, 19, 280, 806, 158, 635, 439, 825, 241, 439, 502, 491, 489, 447, 900, 562, 570, 562, 447, 793, 902, 1012, 146, 46, 41, 867, 912, 487, 558, 833, 557, 331, 180, 696, 380, 562, 983, 1015, 1015, 895, 560, 373, 872, 633, 772, 772, 1013, 503, 41, 694, 693, 180, 779, 994, 874, 443, 546, 377, 358, 847, 658, 258, 498, 980, 958, 109, 992, 33, 934, 497, 384, 296, 429, 160, 256, 588, 16, 51, 82, 40, 217, 978, 926, 755, 27, 675, 586, 586, 436, 665, 806, 819, 616, 1013, 782, 388, 1008, 616, 772, 464, 380, 927, 977, 860, 743, 944, 528, 41, 552, 291, 799, 755, 977], [899, 322, 467, 322, 1012, 63, 51, 537, 641, 194, 529, 308, 437, 957, 812, 498, 986, 901, 902, 889, 979, 745, 591, 8, 709, 590, 583, 160, 267, 693, 711, 880, 475, 948, 937, 518, 469, 330, 586, 859, 620, 499, 742, 323, 208, 602, 765, 18, 279, 283, 717, 322, 416, 832, 8, 989, 173, 194, 694, 225, 376, 237, 309, 989, 253, 630, 757, 412, 714, 835, 1018, 671, 136, 178, 146, 932, 625, 847, 618, 917, 153, 1018, 256, 250, 905, 168, 923, 312, 547, 903, 417, 1010, 398, 462, 592, 63, 580, 953, 761, 313, 961, 1012, 525, 16, 16, 837, 882, 828, 882, 595, 416, 468, 884, 988, 289, 467, 701, 916, 813, 173, 813, 1019, 1019, 1013, 346, 534, 534, 628, 173, 701, 701]], 'instruction': 'Considerably abate the bass frequencies.'}]\n",
      "all_instruction: ['Considerably abate the bass frequencies.']\n"
     ]
    }
   ],
   "source": [
    "observation_list = []\n",
    "for i in range(data_len):\n",
    "    observation_list.append(\n",
    "        {\n",
    "            \"input\": \"\",\n",
    "            \"src_encodec\": all_src_encodec[i],\n",
    "            \"instruction\": all_instruction[i],\n",
    "        }\n",
    "    )\n",
    "    # print(\"src_encodec:\", observation_list[i][\"src_encodec\"][0])\n",
    "    # print(\"instruction:\", all_instruction[i])\n",
    "    \n",
    "# pop the first one\n",
    "observation_list.pop(0)\n",
    "all_instruction.pop(0)\n",
    "observation_list.pop(0)\n",
    "all_instruction.pop(0)\n",
    "print(\"observation_list:\", observation_list)\n",
    "print(\"all_instruction:\", all_instruction)\n",
    "\n",
    "# for i in range(data_len):\n",
    "#     observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[i], 'instruction': all_instruction[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"observation_list:\", observation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name:  BartForConditionalGeneration\n",
      "----------------------------- reset -----------------------------\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "args_predict = SimpleNamespace(\n",
    "    output_path=f\"{base_path}/output/{ts}/example.wav\", seed=0, device=\"cuda\"\n",
    ")\n",
    "\n",
    "env = MyRLEnv(\n",
    "    ar_model,\n",
    "    ar_tokenizer,\n",
    "    nar_model,\n",
    "    nar_tokenizer,\n",
    "    args_predict,\n",
    "    observation_input=observation_list,\n",
    "    compare_sample=1,\n",
    ")\n",
    "actor = TextRLActor(env = env, model = ar_model, tokenizer = ar_tokenizer)\n",
    "# agent = actor.agent_ppo(update_interval=1800, minibatch_size=256, epochs=10, lr=3e-8)\n",
    "# agent = actor.agent_ppo(update_interval=1200, minibatch_size=128, epochs=10)\n",
    "# agent = actor.agent_ppo(update_interval=1000, minibatch_size=128, epochs=10, lr=3e-8)\n",
    "update_interval = 1000\n",
    "minibatch_size = 512\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "# agent = actor.agent_ppo(update_interval=1000, minibatch_size=512, epochs=10, lr=0.001)\n",
    "# agent = actor.agent_ppo(update_interval=1000, minibatch_size=512, epochs=10, lr=0.01, entropy_coef=0.1)\n",
    "# agent = actor.agent_ppo(update_interval=1000, minibatch_size=2048, epochs=1, lr=0.01, entropy_coef=0.1)\n",
    "# agent = actor.agent_ppo(update_interval=100, minibatch_size=1024, epochs=1, lr=0.05, entropy_coef=0.5)\n",
    "# agent = actor.agent_ppo(update_interval=100, minibatch_size=1024, epochs=1, lr=0.01, entropy_coef=0.5)\n",
    "# agent = actor.agent_ppo(update_interval=2048, minibatch_size=32, epochs=1, lr=0.01, entropy_coef=0.1)\n",
    "agent = actor.agent_ppo(update_interval=2048, minibatch_size=32, epochs=1, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "output_log_path = f\"log/log_{ts}.log\"\n",
    "output_file_path = f\"log/output_{ts}.txt\"\n",
    "\n",
    "if not os.path.exists(\"log\"):\n",
    "    os.makedirs(\"log\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "handlers = logger.handlers[:]\n",
    "for handler in handlers:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "file_handler = logging.FileHandler(output_log_path)\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBysk9MiHR2D",
    "outputId": "4086dcd7-6d19-44bc-e1b0-fa764f873301",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages/pfrl/agents/ppo.py:138: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  actions = torch.tensor([b[\"action\"] for b in dataset], device=device)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import pfrl\n",
    "\n",
    "start_time = time.time()\n",
    "pfrl_outdir = f\"ckpt/train_{ts}\"\n",
    "\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = f\n",
    "    print(f\"update_interval = {update_interval}, minibatch_size = {minibatch_size}, epochs = {epochs}, lr = {lr}\")\n",
    "    pfrl.experiments.train_agent_with_evaluation(\n",
    "        agent,\n",
    "        env,\n",
    "        steps=1000000,\n",
    "        eval_n_steps=None,\n",
    "        eval_n_episodes=2,\n",
    "        train_max_episode_len=10000,\n",
    "        eval_interval=1000,\n",
    "        outdir=pfrl_outdir,\n",
    "        logger=logger,\n",
    "        use_tensorboard=True,\n",
    "        checkpoint_freq=5000,\n",
    "    )\n",
    "    sys.stdout = original_stdout   \n",
    "    \n",
    "print(\"Output has been written to\", output_file_path)\n",
    "print(\"used time: \", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpAwe42ES-5w",
    "outputId": "bb12c0d2-1916-4076-8f98-b20d2a2e4e57"
   },
   "outputs": [],
   "source": [
    "agent.load(pfrl_outdir + \"/best\")\n",
    "actor.predict(observation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import read_pickle\n",
    "# ts = \"0430-1250\"\n",
    "# # len of the pickle file\n",
    "# dir_path = f\"{base_path}/replay_buffer/{ts}\"\n",
    "# length = len(os.listdir(dir_path))\n",
    "# for i in range(length):\n",
    "#     pickle_file = f\"replay_buffer_update_{i}.pkl\"\n",
    "#     pickle_data = read_pickle.load_pickle(file_path = f'{base_path}/replay_buffer/{ts}/{pickle_file}')\n",
    "#     length_of_pickle_data = len(pickle_data[0])\n",
    "#     length_of_pickle_data1 = len(pickle_data[1])\n",
    "#     if len(pickle_data)>= 3:\n",
    "#         length_of_pickle_data2 = len(pickle_data[2])\n",
    "#         print(f\"length of {pickle_file}: {length_of_pickle_data} and {length_of_pickle_data1} and {length_of_pickle_data2}\")\n",
    "#     else:\n",
    "#         print(f\"length of {pickle_file}: {length_of_pickle_data} and {length_of_pickle_data1}\") \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c6c77b12b02a1c2aaa91a9fb9cc35bb3c4bbfb7b716f83ac7b2b57ffb1247cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
