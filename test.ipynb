{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5gZSqIG1ah"
   },
   "source": [
    "# Controllable generation via RL to let Elon Musk speak ill of DOGE\n",
    "> How to control text generation through a sentiment classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from transformers import (AutoTokenizer, BartForConditionalGeneration)\n",
    "import logging\n",
    "import sys\n",
    "import pfrl\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')\n",
    "\n",
    "# define path\n",
    "base_path = '/work/b0990106x/TextRL'\n",
    "agent_input_dir = f'{base_path}/data-encodec'\n",
    "agent_output_dir = f'{base_path}/output'\n",
    "env_input_dir = agent_output_dir\n",
    "env_output_dir = agent_input_dir\n",
    "\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "ar_model.to(device)\n",
    "\n",
    "dataset = load_from_disk(agent_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_src_encodec_layers = []\n",
    "all_src_encodec = []\n",
    "all_instruction = []\n",
    "all_instruction_ids = []\n",
    "\n",
    "data_len = len(dataset)\n",
    "print(data_len)\n",
    "\n",
    "data_len = 22 # for testing\n",
    "layer_len = 8\n",
    "\n",
    "for i in range(layer_len):\n",
    "    all_src_encodec_layers.append(dataset[f\"src_encodec_{i}\"])\n",
    "\n",
    "for i in range(data_len):\n",
    "    src_encodec = []\n",
    "    for j in range(layer_len):        \n",
    "        src_encodec.append(all_src_encodec_layers[j][i])\n",
    "    all_src_encodec.append(src_encodec)\n",
    "\n",
    "for i in range(data_len):\n",
    "    all_instruction.append(dataset[\"instruction\"][i])\n",
    "    all_instruction_ids.append(ar_tokenizer(all_instruction[i])[\"input_ids\"][1 : -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/work/b0990106x/TextRL/vc')\n",
    "\n",
    "from importlib import reload\n",
    "import textrl\n",
    "reload(textrl)\n",
    "\n",
    "from textrl import TextRLEnv,TextRLActor\n",
    "# reload(sys.modules['vc.trainer_encodec_vc_inference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NISQA.nisqa.NISQA_model import nisqaModel\n",
    "\n",
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
    "        reward = 0\n",
    "        if finish or len(predicted_list) >= self.env_max_length:\n",
    "            args_nisqa = {\n",
    "                'mode': 'predict_file', \n",
    "                'pretrained_model': f'{base_path}/NISQA/weights/nisqa.tar', \n",
    "                'deg': f'{base_path}/output/example.wav', \n",
    "                'data_dir': None, \n",
    "                'output_dir': f'{base_path}/NISQA/result',\n",
    "                'csv_file': None, \n",
    "                'csv_deg': None,  \n",
    "                'num_workers': 0, \n",
    "                'bs': 1,\n",
    "                'ms_channel': None\n",
    "            }\n",
    "            args_nisqa['tr_bs_val'] = args_nisqa['bs']\n",
    "            args_nisqa['tr_num_workers'] = args_nisqa['num_workers']\n",
    "            \n",
    "            nisqa = nisqaModel(args_nisqa)\n",
    "            prediction = nisqa.predict()\n",
    "            reward = float(prediction['mos_pred'].iloc[0])\n",
    "            print(\"input_item : \",input_item['input'])\n",
    "            print(\"predicted_list: \", predicted_list)\n",
    "            print(\"reward: \", reward) \n",
    "                       \n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqF7mNCY5tdO"
   },
   "source": [
    "**fit one example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_list = []\n",
    "for i in range(data_len):\n",
    "    observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[i], 'instruction': all_instruction[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data_len):\n",
    "    print(f\"Instruction {i}: \", observation_list[i]['instruction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtGfk03eHOv_"
   },
   "outputs": [],
   "source": [
    "env = MyRLEnv(ar_model, ar_tokenizer, nar_model, nar_tokenizer, observation_input=observation_list, compare_sample=1)\n",
    "actor = TextRLActor(env, ar_model, ar_tokenizer)\n",
    "agent = actor.agent_ppo(update_interval=3, minibatch_size=3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.predict(observation_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBysk9MiHR2D",
    "outputId": "4086dcd7-6d19-44bc-e1b0-fa764f873301",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "output_file_path = 'log.txt'\n",
    "\n",
    "# with open(output_file_path, 'w') as f:\n",
    "#     original_stdout = sys.stdout\n",
    "#     sys.stdout = f\n",
    "\n",
    "#     pfrl_outdir = 'train_steps_900'\n",
    "#     pfrl.experiments.train_agent_with_evaluation(\n",
    "#         agent,\n",
    "#         env,\n",
    "#         steps=900, # train the agent for n steps\n",
    "#         eval_n_steps=None, \n",
    "#         eval_n_episodes=3, # evaluate n episodes per evaluation\n",
    "#         train_max_episode_len=1000,  \n",
    "#         eval_interval=5, # evaluation every n episodes\n",
    "#         outdir=pfrl_outdir, \n",
    "#     )\n",
    "#     # pfrl.experiments.train_agent_with_evaluation(\n",
    "#     #     agent,\n",
    "#     #     env,\n",
    "#     #     steps=900,  \n",
    "#     #     eval_n_steps=None, \n",
    "#     #     eval_n_episodes=6, \n",
    "#     #     train_max_episode_len=1000,  \n",
    "#     #     eval_interval=3, \n",
    "#     #     outdir=pfrl_outdir, \n",
    "#     # )\n",
    "\n",
    "#     sys.stdout = original_stdout\n",
    "\n",
    "pfrl_outdir = 'train_steps_900'\n",
    "pfrl.experiments.train_agent_with_evaluation(\n",
    "        agent,\n",
    "        env,\n",
    "        steps=900, # train the agent for n steps\n",
    "        eval_n_steps=None, \n",
    "        eval_n_episodes=3, # evaluate n episodes per evaluation\n",
    "        train_max_episode_len=1000,  \n",
    "        eval_interval=5, # evaluation every n episodes\n",
    "        outdir=pfrl_outdir, \n",
    "    )\n",
    "\n",
    "print('Output has been written to', output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B7rMPRU5zsM"
   },
   "source": [
    "loading the best result and predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrkYGPjYTIcS"
   },
   "outputs": [],
   "source": [
    "agent.load(pfrl_outdir + '/best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpAwe42ES-5w",
    "outputId": "bb12c0d2-1916-4076-8f98-b20d2a2e4e57"
   },
   "outputs": [],
   "source": [
    "actor.predict(observation_list[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c6c77b12b02a1c2aaa91a9fb9cc35bb3c4bbfb7b716f83ac7b2b57ffb1247cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
