{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5gZSqIG1ah"
   },
   "source": [
    "# Controllable generation via RL to let Elon Musk speak ill of DOGE\n",
    "> How to control text generation through a sentiment classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgBsD1fa0hJn"
   },
   "outputs": [],
   "source": [
    "# %pip install pfrl@git+https://github.com/voidful/pfrl.git\n",
    "# %pip install textrl==0.2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from vc.encodec_model.nar_bart_model import NARBartForConditionalGeneration\n",
    "from transformers import (AutoTokenizer, BartForConditionalGeneration)\n",
    "import logging\n",
    "import sys\n",
    "import pfrl\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')\n",
    "\n",
    "# define path\n",
    "base_path = '/work/b0990106x/TextRL'\n",
    "agent_input_dir = f'{base_path}/data-encodec'\n",
    "agent_output_dir = f'{base_path}/output'\n",
    "env_input_dir = agent_output_dir\n",
    "env_output_dir = agent_input_dir\n",
    "\n",
    "ar_checkpoint = \"lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans\"\n",
    "nar_checkpoint = \"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ar_tokenizer = AutoTokenizer.from_pretrained(ar_checkpoint)\n",
    "ar_model = BartForConditionalGeneration.from_pretrained(ar_checkpoint)\n",
    "nar_tokenizer = AutoTokenizer.from_pretrained(nar_checkpoint)\n",
    "nar_model = NARBartForConditionalGeneration.from_pretrained(nar_checkpoint)\n",
    "ar_model.to(device)\n",
    "\n",
    "dataset = load_from_disk(agent_input_dir)\n",
    "# source = dataset[f\"src_encodec_0\"][0]\n",
    "# instruction = dataset[\"instruction\"][0]\n",
    "# transcription = dataset[\"transcription\"][0]\n",
    "# instruction_ids = ar_tokenizer(instruction)[\"input_ids\"][1 : -1]\n",
    "# transcription_ids = ar_tokenizer(transcription)[\"input_ids\"][1 : -1]\n",
    "# src_encodec_ids = ar_tokenizer.convert_tokens_to_ids(\n",
    "#     [f\"v_tok_{u}\" for u in dataset[f\"src_encodec_0\"][0]])\n",
    "# src_encodec_str = ar_tokenizer.convert_tokens_to_string(\n",
    "#     [f\"v_tok_{u}\" for u in dataset[f\"src_encodec_0\"][0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "all_src_encodec_layers = []\n",
    "all_src_encodec = []\n",
    "all_instruction = []\n",
    "all_instruction_ids = []\n",
    "\n",
    "# data_len = len(dataset)\n",
    "data_len = 200 # for testing\n",
    "layer_len = 8\n",
    "\n",
    "for i in range(layer_len):\n",
    "    all_src_encodec_layers.append(dataset[f\"src_encodec_{i}\"])\n",
    "\n",
    "for i in range(data_len):\n",
    "    src_encodec = []\n",
    "    for j in range(layer_len):        \n",
    "        src_encodec.append(all_src_encodec_layers[j][i])\n",
    "    all_src_encodec.append(src_encodec)\n",
    "\n",
    "for i in range(data_len):\n",
    "    all_instruction.append(dataset[\"instruction\"][i])\n",
    "    all_instruction_ids.append(ar_tokenizer(all_instruction[i])[\"input_ids\"][1 : -1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data validity\n",
    "# all data in all_src_encodec must be the numbers instead of strings\n",
    "# for i in range(data_len):\n",
    "#     for j in range(layer_len):\n",
    "#         assert isinstance(all_src_encodec[i][j], list)\n",
    "#         for k in range(len(all_src_encodec[i][j])):\n",
    "#             assert isinstance(all_src_encodec[i][j][k], int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run voice conversion model to get the target speech\n",
    "# import sys\n",
    "# sys.path.append('/work/b0990106x/TextRL/vc')\n",
    "# from vc.trainer_encodec_vc_inference import get_ar_prediction, get_ar_prediction_without_writing_files\n",
    "# from types import SimpleNamespace\n",
    "\n",
    "# args_predict = SimpleNamespace(\n",
    "#     output_path = \"/work/b0990106x/TextRL/output/example.wav\",\n",
    "#     seed = 0,\n",
    "#     device = \"cuda\"\n",
    "# )    \n",
    "\n",
    "# single_src_encodec = all_src_encodec[0]\n",
    "# single_instruction = all_instruction[0]\n",
    "# print(\"single_src_encodec: \", single_src_encodec)\n",
    "# print(\"single_instruction: \", single_instruction)\n",
    "\n",
    "# decode_ar = get_ar_prediction(args_predict, ar_model, nar_model, ar_tokenizer, nar_tokenizer, single_src_encodec, single_instruction)\n",
    "# decode_ar_ids = ar_tokenizer.convert_tokens_to_ids(\n",
    "#     [f\"v_tok_{u}\" for u in decode_ar])\n",
    "# decode_ar_str = ar_tokenizer.convert_tokens_to_string(\n",
    "#     [f\"v_tok_{u}\" for u in decode_ar])\n",
    "    \n",
    "# print(\"decode_ar: \", decode_ar)\n",
    "# print(\"decode_ar_ids: \", decode_ar_ids)\n",
    "# print(\"decode_ar_str: \", decode_ar_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # demo how the tokenization works\n",
    "\n",
    "# # source speech before tokenization\n",
    "# print('source: ', source)\n",
    "# print('size of source: ', len(source))\n",
    "# print('src_encodec_ids: ', src_encodec_ids)\n",
    "# print('size of src_encodec_ids: ', len(src_encodec_ids))\n",
    "# print('src_encodec_str: ', src_encodec_str)\n",
    "# print('size of src_encodec_str: ', len(src_encodec_str))\n",
    "# # source speech after tokenization\n",
    "# tokens = ar_tokenizer.convert_ids_to_tokens(src_encodec_ids)\n",
    "# ids = ar_tokenizer.convert_tokens_to_ids(tokens)\n",
    "# print('ar_tokenizer.convert_ids_to_tokens(src_encodec_ids): ', tokens)\n",
    "# print('ar_tokenizer.convert_tokens_to_ids(tokens): ', ids)\n",
    "# print('ar_tokenizer.convert_tokens_to_ids(tokens): ', ids)\n",
    "# print('size of ar_tokenizer.convert_ids_to_tokens(src_encodec_ids): ', len(tokens))\n",
    "# # instruction before tokenization\n",
    "# print(instruction)\n",
    "# # instruction after tokenization\n",
    "# print(ar_tokenizer.convert_ids_to_tokens(instruction_ids))\n",
    "# # transcription before tokenization\n",
    "# print(transcription)\n",
    "# # transcription after tokenization\n",
    "# print(ar_tokenizer.convert_ids_to_tokens(transcription_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inference all data and replace the src_encodec[0] with the decode_ar\n",
    "# all_decode_ar = []\n",
    "# all_decode_ar_str = []\n",
    "# for i in range(data_len):\n",
    "#     print(f\"Processing {i}...\")\n",
    "#     decode_ar = get_ar_prediction_without_writing_files(args_predict, ar_model, nar_model, ar_tokenizer, nar_tokenizer, all_src_encodec[i], all_instruction[i])\n",
    "#     all_decode_ar.append(decode_ar)\n",
    "    \n",
    "#     decode_ar_str = ar_tokenizer.convert_tokens_to_string(\n",
    "#         [f\"v_tok_{u}\" for u in decode_ar])\n",
    "#     all_decode_ar_str.append(decode_ar_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/work/b0990106x/TextRL/vc')\n",
    "\n",
    "from importlib import reload\n",
    "import textrl\n",
    "reload(textrl)\n",
    "\n",
    "from textrl import TextRLEnv,TextRLActor\n",
    "reload(sys.modules['vc.trainer_encodec_vc_inference'])\n",
    "\n",
    "from vc.trainer_encodec_vc_inference import get_ar_prediction, get_ar_prediction_without_writing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NISQA.nisqa.NISQA_model import nisqaModel\n",
    "\n",
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
    "        reward = 0\n",
    "        if finish or len(predicted_list) >= self.env_max_length:\n",
    "            # single_src_encodec = input_item['src_encodec']\n",
    "            # single_instruction = input_item['instruction']\n",
    "            # decode_ar = get_ar_prediction(args_predict, ar_model, nar_model, ar_tokenizer, nar_tokenizer, single_src_encodec, single_instruction)\n",
    "            \n",
    "            args_nisqa = {\n",
    "                'mode': 'predict_file', \n",
    "                'pretrained_model': f'{base_path}/NISQA/weights/nisqa.tar', \n",
    "                'deg': f'{base_path}/output/example.wav', \n",
    "                'data_dir': None, \n",
    "                'output_dir': f'{base_path}/NISQA/result',\n",
    "                'csv_file': None, \n",
    "                'csv_deg': None,  \n",
    "                'num_workers': 0, \n",
    "                'bs': 1,\n",
    "                'ms_channel': None\n",
    "            }\n",
    "            args_nisqa['tr_bs_val'] = args_nisqa['bs']\n",
    "            args_nisqa['tr_num_workers'] = args_nisqa['num_workers']\n",
    "            \n",
    "            nisqa = nisqaModel(args_nisqa)\n",
    "            prediction = nisqa.predict()\n",
    "            reward = float(prediction['mos_pred'].iloc[0])\n",
    "            print(\"input_item : \",input_item['input'])\n",
    "            print(\"predicted_list: \", predicted_list)\n",
    "            print(\"reward: \", reward) \n",
    "                       \n",
    "        return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqF7mNCY5tdO"
   },
   "source": [
    "**fit one example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation_list = [{'input':src_encodec_str}]\n",
    "# put all decode_ar to the observation_list\n",
    "observation_list = []\n",
    "for i in range(data_len):\n",
    "    # observation_list.append({'input':all_decode_ar_str[i], 'src_encodec':all_src_encodec[i], 'instruction':all_instruction[i]})\n",
    "    observation_list.append({'input': \"\", 'src_encodec': all_src_encodec[i], 'instruction': all_instruction[i]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtGfk03eHOv_"
   },
   "outputs": [],
   "source": [
    "env = MyRLEnv(ar_model, ar_tokenizer, nar_model, nar_tokenizer, observation_input=observation_list, compare_sample=1)\n",
    "actor = TextRLActor(env, ar_model, ar_tokenizer)\n",
    "agent = actor.agent_ppo(update_interval=100, minibatch_size=3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_str = actor.predict(observation_list[0])\n",
    "\n",
    "# # decode the predicted token\n",
    "# predicted_ids = ar_tokenizer.convert_tokens_to_ids(predicted_str)\n",
    "# decoded_text = ar_tokenizer.decode(predicted_ids, skip_special_tokens=True)\n",
    "# print(\"predicted ids: \", predicted_ids)\n",
    "# print(\"decoded text: \", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBysk9MiHR2D",
    "outputId": "4086dcd7-6d19-44bc-e1b0-fa764f873301",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pfrl.experiments.train_agent_with_evaluation(\n",
    "    agent,\n",
    "    env,\n",
    "    steps=4,\n",
    "    eval_n_steps=None,\n",
    "    eval_n_episodes=2,       \n",
    "    train_max_episode_len=5,  \n",
    "    eval_interval=10,\n",
    "    outdir='train_200', \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B7rMPRU5zsM"
   },
   "source": [
    "loading the best result and predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrkYGPjYTIcS"
   },
   "outputs": [],
   "source": [
    "agent.load(\"./elon_musk_dogecoin/best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpAwe42ES-5w",
    "outputId": "bb12c0d2-1916-4076-8f98-b20d2a2e4e57"
   },
   "outputs": [],
   "source": [
    "actor.predict(observation_list[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c6c77b12b02a1c2aaa91a9fb9cc35bb3c4bbfb7b716f83ac7b2b57ffb1247cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
