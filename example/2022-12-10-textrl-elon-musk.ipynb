{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5gZSqIG1ah"
   },
   "source": [
    "# Controllable generation via RL to let Elon Musk speak ill of DOGE\n",
    "> How to control text generation through a sentiment classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tgBsD1fa0hJn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pfrl@ git+https://github.com/voidful/pfrl.git\n",
      "  Cloning https://github.com/voidful/pfrl.git to /tmp/pip-install-du1ubgh_/pfrl_d7f21da864944d2c8f2a8f537dfcb8c8\n",
      "  Running command git clone --filter=blob:none -q https://github.com/voidful/pfrl.git /tmp/pip-install-du1ubgh_/pfrl_d7f21da864944d2c8f2a8f537dfcb8c8\n",
      "  Resolved https://github.com/voidful/pfrl.git to commit bd679022d91902a3c88066d2646ad69b30d5684a\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (1.10.1)\n",
      "Collecting gym>=0.9.7\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     |████████████████████████████████| 721 kB 1.1 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (1.20.3)\n",
      "Requirement already satisfied: pillow in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from pfrl@ git+https://github.com/voidful/pfrl.git) (8.4.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting importlib-metadata>=4.8.0\n",
      "  Downloading importlib_metadata-7.0.1-py3-none-any.whl (23 kB)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: typing_extensions in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from torch>=1.3.0->pfrl@ git+https://github.com/voidful/pfrl.git) (4.9.0)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Building wheels for collected packages: pfrl, gym\n",
      "  Building wheel for pfrl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pfrl: filename=pfrl-0.4.0-py3-none-any.whl size=155504 sha256=950dad1f36449504d8145a709b5e06e834a8d5f77b00701da21aeb35f6be4d6e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ue8da_4w/wheels/4e/7a/0d/6d90ea0eecefee2bcf373177932fd54e84b41ef5190472e2db\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827634 sha256=cf63542ca0a456e6e07491f93c3734594dad17c991d46871ad02a60b1eeb66c9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ue8da_4w/wheels/af/2b/30/5e78b8b9599f2a2286a582b8da80594f654bf0e18d825a4405\n",
      "Successfully built pfrl gym\n",
      "Installing collected packages: zipp, importlib-metadata, gym-notices, cloudpickle, gym, filelock, pfrl\n",
      "Successfully installed cloudpickle-3.0.0 filelock-3.13.1 gym-0.26.2 gym-notices-0.0.8 importlib-metadata-7.0.1 pfrl-0.4.0 zipp-3.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting textrl==0.2.15\n",
      "  Downloading textrl-0.2.15-py3-none-any.whl (18 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "     |████████████████████████████████| 8.4 MB 1.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: gym in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from textrl==0.2.15) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym->textrl==0.2.15) (1.20.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym->textrl==0.2.15) (7.0.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym->textrl==0.2.15) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from gym->textrl==0.2.15) (3.0.0)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 49.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (6.0)\n",
      "Requirement already satisfied: filelock in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (3.13.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "     |████████████████████████████████| 773 kB 51.4 MB/s            \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "     |████████████████████████████████| 330 kB 56.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (23.2)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "     |████████████████████████████████| 3.6 MB 48.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from transformers->textrl==0.2.15) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers->textrl==0.2.15) (4.9.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "     |████████████████████████████████| 170 kB 15.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from importlib-metadata>=4.8.0->gym->textrl==0.2.15) (3.17.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from requests->transformers->textrl==0.2.15) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from requests->transformers->textrl==0.2.15) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from requests->transformers->textrl==0.2.15) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages (from requests->transformers->textrl==0.2.15) (3.3.2)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, safetensors, regex, transformers, textrl\n",
      "Successfully installed fsspec-2024.2.0 huggingface-hub-0.20.3 regex-2023.12.25 safetensors-0.4.2 textrl-0.2.15 tokenizers-0.15.2 transformers-4.37.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pfrl@git+https://github.com/voidful/pfrl.git\n",
    "%pip install textrl==0.2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c8BT6ZwpNke-"
   },
   "outputs": [],
   "source": [
    "from textrl import TextRLEnv,TextRLActor\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelWithLMHead\n",
    "import logging\n",
    "import sys\n",
    "import pfrl\n",
    "import torch\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re1cxoPZ4wgf"
   },
   "source": [
    "**Using a pre-trained model, it can generate elonmusk's style tweets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f0TqcFITHHdX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(59481, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(59481, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(59481, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=59481, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"lca0503/speech-chatgpt-base-nar-v2-epoch4-wotrans\")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"huggingtweets/elonmusk\")  \n",
    "# model = AutoModelWithLMHead.from_pretrained(\"huggingtweets/elonmusk\")\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "342ChdlM5CXv"
   },
   "source": [
    "**a sentiment classifier for rl reward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYRgFPW_HrJo",
    "outputId": "a78366c1-d0ba-4220-97f2-d3fc0577a99a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentiment = pipeline('sentiment-analysis',model=\"cardiffnlp/twitter-roberta-base-sentiment\",tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment\",device=0,return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o47CRT8TKqvn"
   },
   "outputs": [],
   "source": [
    "transformers_logger = logging.getLogger('transformers')\n",
    "transformers_logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgFrS5gQIAxR",
    "outputId": "5336889f-b05b-415e-d368-e4d953a5591e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.9338533878326416},\n",
       "  {'label': 'LABEL_1', 'score': 0.0601188987493515},\n",
       "  {'label': 'LABEL_2', 'score': 0.006027725990861654}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"dogecoin is bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhVcFdwjJzjW",
    "outputId": "c397a19c-c53c-4013-e45b-069b65eaf615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338533878326416"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"dogecoin is bad\")[0][0]['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfjPrvcK5N5e"
   },
   "source": [
    "set our text generation reward, inverse perplexity + sentiment classifier.\n",
    "- inverse perplexity make sure the generated sentence probability will be high.\n",
    "- sentiment classifier can make the generate more negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OgNGUk99HMtT"
   },
   "outputs": [],
   "source": [
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
    "      reward = 0\n",
    "      if finish or len(predicted_list) >= self.env_max_length:\n",
    "        predicted_text = tokenizer.convert_tokens_to_string(predicted_list[0])\n",
    "        # sentiment classifier\n",
    "        reward = sentiment(input_item[0]+predicted_text)[0][0]['score'] * 10\n",
    "      return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqF7mNCY5tdO"
   },
   "source": [
    "**fit one example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cy4tCfslKGd4"
   },
   "outputs": [],
   "source": [
    "observaton_list = [{'input':'i think dogecoin is'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wtGfk03eHOv_"
   },
   "outputs": [],
   "source": [
    "env = MyRLEnv(model, tokenizer, observation_input=observaton_list,compare_sample=1)\n",
    "actor = TextRLActor(env,model,tokenizer)\n",
    "agent = actor.agent_ppo(update_interval=100, minibatch_size=3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sBBy1yjIdtP",
    "outputId": "62125633-6c76-47eb-c207-ebf33a99e78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>v_tok_2201v_tok_4870v_tok_4689v_tok_4038v_tok_4689v_tok_4038v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.predict(observaton_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBysk9MiHR2D",
    "outputId": "4086dcd7-6d19-44bc-e1b0-fa764f873301",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages/pfrl/agents/ppo.py:132: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180549130/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  actions = torch.tensor([b[\"action\"] for b in dataset], device=device)\n",
      "/home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages/textrl/actor.py:293: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([3, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss_value_func = F.mse_loss(vs_pred, vs_teacher)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdir:elon_musk_dogecoin step:100 episode:0 R:0\n",
      "statistics:[('average_value', -0.0058390973), ('average_entropy', 7.394447), ('average_value_loss', 0.0037143150047631935), ('average_policy_loss', 0.005632610293105245), ('n_updates', 334), ('explained_variance', -14.406542544507479)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation episode 0 length:100 R:0\n",
      "The best score is updated -3.4028235e+38 -> 0.0\n",
      "Saved the agent to elon_musk_dogecoin/best\n",
      "outdir:elon_musk_dogecoin step:200 episode:1 R:0\n",
      "statistics:[('average_value', 0.007455408), ('average_entropy', 7.2373095), ('average_value_loss', 0.004107499678502791), ('average_policy_loss', 0.0016428552218712867), ('n_updates', 668), ('explained_variance', -51.67072420067641)]\n",
      "evaluation episode 0 length:100 R:0\n",
      "outdir:elon_musk_dogecoin step:300 episode:2 R:0\n",
      "statistics:[('average_value', -0.0097230775), ('average_entropy', 7.222486), ('average_value_loss', 0.0031916120633104584), ('average_policy_loss', -0.008724038759246468), ('n_updates', 1002), ('explained_variance', -13.687780137957585)]\n",
      "evaluation episode 0 length:100 R:0\n",
      "Saved the agent to elon_musk_dogecoin/300_finish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<textrl.actor.TextPPO at 0x7f2883bdbee0>,\n",
       " [{'average_value': -0.0058390973,\n",
       "   'average_entropy': 7.394447,\n",
       "   'average_value_loss': 0.0037143150047631935,\n",
       "   'average_policy_loss': 0.005632610293105245,\n",
       "   'n_updates': 334,\n",
       "   'explained_variance': -14.406542544507479,\n",
       "   'eval_score': 0.0},\n",
       "  {'average_value': 0.007455408,\n",
       "   'average_entropy': 7.2373095,\n",
       "   'average_value_loss': 0.004107499678502791,\n",
       "   'average_policy_loss': 0.0016428552218712867,\n",
       "   'n_updates': 668,\n",
       "   'explained_variance': -51.67072420067641,\n",
       "   'eval_score': 0.0},\n",
       "  {'average_value': -0.0097230775,\n",
       "   'average_entropy': 7.222486,\n",
       "   'average_value_loss': 0.0031916120633104584,\n",
       "   'average_policy_loss': -0.008724038759246468,\n",
       "   'n_updates': 1002,\n",
       "   'explained_variance': -13.687780137957585,\n",
       "   'eval_score': 0.0}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfrl.experiments.train_agent_with_evaluation(\n",
    "    agent,\n",
    "    env,\n",
    "    steps=300,\n",
    "    eval_n_steps=None,\n",
    "    eval_n_episodes=1,       \n",
    "    train_max_episode_len=100,  \n",
    "    eval_interval=10,\n",
    "    outdir='elon_musk_dogecoin', \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B7rMPRU5zsM"
   },
   "source": [
    "loading the best result and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FrkYGPjYTIcS"
   },
   "outputs": [],
   "source": [
    "agent.load(\"./elon_musk_dogecoin/best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpAwe42ES-5w",
    "outputId": "bb12c0d2-1916-4076-8f98-b20d2a2e4e57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>v_tok_2201v_tok_4870v_tok_4689v_tok_4038v_tok_4689v_tok_4038v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689v_tok_4689']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.predict(observaton_list[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c6c77b12b02a1c2aaa91a9fb9cc35bb3c4bbfb7b716f83ac7b2b57ffb1247cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
