{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5gZSqIG1ah"
   },
   "source": [
    "# Controllable generation via RL to let Elon Musk speak ill of DOGE\n",
    "> How to control text generation through a sentiment classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tgBsD1fa0hJn"
   },
   "outputs": [],
   "source": [
    "# %pip install pfrl@git+https://github.com/voidful/pfrl.git\n",
    "# %pip install textrl==0.2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "c8BT6ZwpNke-"
   },
   "outputs": [],
   "source": [
    "from textrl import TextRLEnv,TextRLActor\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelWithLMHead\n",
    "import logging\n",
    "import sys\n",
    "import pfrl\n",
    "import torch\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Re1cxoPZ4wgf"
   },
   "source": [
    "**Using a pre-trained model, it can generate elonmusk's style tweets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f0TqcFITHHdX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1322: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huggingtweets/elonmusk\")  \n",
    "model = AutoModelWithLMHead.from_pretrained(\"huggingtweets/elonmusk\")\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "342ChdlM5CXv"
   },
   "source": [
    "**a sentiment classifier for rl reward**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYRgFPW_HrJo",
    "outputId": "a78366c1-d0ba-4220-97f2-d3fc0577a99a",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentiment = pipeline('sentiment-analysis',model=\"cardiffnlp/twitter-roberta-base-sentiment\",tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment\",device=0,return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "o47CRT8TKqvn"
   },
   "outputs": [],
   "source": [
    "transformers_logger = logging.getLogger('transformers')\n",
    "transformers_logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgFrS5gQIAxR",
    "outputId": "5336889f-b05b-415e-d368-e4d953a5591e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.9338533878326416},\n",
       "  {'label': 'LABEL_1', 'score': 0.0601188987493515},\n",
       "  {'label': 'LABEL_2', 'score': 0.006027725990861654}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"dogecoin is bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do -> 4598\n",
      "ge -> 469\n",
      "coin -> 3630\n",
      "Ġis -> 318\n",
      "Ġbad -> 2089\n",
      "329 -> Ġfor\n",
      "262 -> Ġthe\n",
      "3773 -> Ġeconomy\n",
      "50256 -> <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# demo how the tokenization works\n",
    "tokens = tokenizer.tokenize(\"dogecoin is bad\")\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "for tokens, token_id in zip(tokens, token_ids):\n",
    "    print(f\"{tokens} -> {token_id}\")\n",
    "    \n",
    "ids = [329, 262, 3773, 50256]\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "\n",
    "for token_id, tokens in zip(ids, tokens):\n",
    "    print(f\"{token_id} -> {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogecoin is bad for the economy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b0990106x/miniconda3/envs/textrl/lib/python3.9/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# demo how the model works\n",
    "output = model.generate(tokenizer.encode(\"dogecoin is bad\", return_tensors='pt').cuda())\n",
    "generated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhVcFdwjJzjW",
    "outputId": "c397a19c-c53c-4013-e45b-069b65eaf615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9338533878326416"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment(\"dogecoin is bad\")[0][0]['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfjPrvcK5N5e"
   },
   "source": [
    "set our text generation reward, inverse perplexity + sentiment classifier.\n",
    "- inverse perplexity make sure the generated sentence probability will be high.\n",
    "- sentiment classifier can make the generate more negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OgNGUk99HMtT"
   },
   "outputs": [],
   "source": [
    "class MyRLEnv(TextRLEnv):\n",
    "    def get_reward(self, input_item, predicted_list, finish): # predicted will be the list of predicted token\n",
    "      reward = 0\n",
    "      if finish or len(predicted_list) >= self.env_max_length:\n",
    "        predicted_text = tokenizer.convert_tokens_to_string(predicted_list[0])\n",
    "        # sentiment classifier\n",
    "        print(\"input_item : \", input_item['input'])\n",
    "        print(\"predicted_text : \", predicted_text)\n",
    "        print(\"predicted_list : \", predicted_list)\n",
    "        # print(sentiment(input_item[0]+predicted_text))\n",
    "        # reward = sentiment(input_item[0]+predicted_text)[0][0]['score'] * 10\n",
    "        reward = sentiment(input_item['input']+predicted_text)[0][0]['score'] * 10\n",
    "      return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqF7mNCY5tdO"
   },
   "source": [
    "**fit one example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cy4tCfslKGd4"
   },
   "outputs": [],
   "source": [
    "observaton_list = [{'input':'i think bitcoin is', 'test': 'hello'},{'input':'i think dogecoin is'},{'input':'i think ethereum is'},{'input':'i think cardano is'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "wtGfk03eHOv_"
   },
   "outputs": [],
   "source": [
    "env = MyRLEnv(model, tokenizer, observation_input=observaton_list,compare_sample=1)\n",
    "actor = TextRLActor(env,model,tokenizer)\n",
    "agent = actor.agent_ppo(update_interval=100, minibatch_size=3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sBBy1yjIdtP",
    "outputId": "62125633-6c76-47eb-c207-ebf33a99e78e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_item :  i think bitcoin is\n",
      "predicted_text :   a good idea<|endoftext|>\n",
      "predicted_list :  [['Ġa', 'Ġgood', 'Ġidea', '<|endoftext|>']]\n"
     ]
    }
   ],
   "source": [
    "predicted_str = actor.predict(observaton_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBysk9MiHR2D",
    "outputId": "4086dcd7-6d19-44bc-e1b0-fa764f873301",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdir:elon_musk_dogecoin step:10 episode:0 R:0\n",
      "statistics:[('average_value', 0.69971454), ('average_entropy', 4.247846), ('average_value_loss', nan), ('average_policy_loss', nan), ('n_updates', 0), ('explained_variance', nan)]\n",
      "input_item :  i think cardano is\n",
      "predicted_text :   the best.<|endoftext|>\n",
      "predicted_list :  [['Ġthe', 'Ġbest', '.', '<|endoftext|>']]\n",
      "evaluation episode 0 length:4 R:0.028983745723962784\n",
      "The best score is updated -3.4028235e+38 -> 0.028983745723962784\n",
      "Saved the agent to elon_musk_dogecoin/best\n",
      "Saved the agent to elon_musk_dogecoin/10_finish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<textrl.actor.TextPPO at 0x7f013f7cfa90>,\n",
       " [{'average_value': 0.69971454,\n",
       "   'average_entropy': 4.247846,\n",
       "   'average_value_loss': nan,\n",
       "   'average_policy_loss': nan,\n",
       "   'n_updates': 0,\n",
       "   'explained_variance': nan,\n",
       "   'eval_score': 0.028983745723962784}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfrl.experiments.train_agent_with_evaluation(\n",
    "    agent,\n",
    "    env,\n",
    "    steps=10,\n",
    "    eval_n_steps=None,\n",
    "    eval_n_episodes=1,       \n",
    "    train_max_episode_len=100,  \n",
    "    eval_interval=1,\n",
    "    outdir='elon_musk_dogecoin', \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B7rMPRU5zsM"
   },
   "source": [
    "loading the best result and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FrkYGPjYTIcS"
   },
   "outputs": [],
   "source": [
    "agent.load(\"./elon_musk_dogecoin/best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpAwe42ES-5w",
    "outputId": "bb12c0d2-1916-4076-8f98-b20d2a2e4e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_item :  i think bitcoin is\n",
      "predicted_text :   a good idea<|endoftext|>\n",
      "predicted_list :  [['Ġa', 'Ġgood', 'Ġidea', '<|endoftext|>']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' a good idea<|endoftext|>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.predict(observaton_list[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "virtual-env-3.10.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c6c77b12b02a1c2aaa91a9fb9cc35bb3c4bbfb7b716f83ac7b2b57ffb1247cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
